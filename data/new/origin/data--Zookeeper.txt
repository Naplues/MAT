//  BUG: Grizzly needs a doc root if you are going to register multiple adapters 
//  we don't need to retry this operation in the case of failure   as ZK will remove ephemeral files and we don't wanna hang   this process when closing if we cannot reconnect to ZK 
//  This is likely a problem, it means that file reloading is broken, probably because the   directory we are watching was deleted or otherwise became inaccessible (unmounted, permissions   changed, ???).   For now, we log an error and exit the watcher thread. 
//  FIXME this was originally 5 seconds, but realistically, on random/slow/virt hosts, there is no way to guarantee this 
//  This is a bit weird but we need to return the address and the number of   bytes (to distinguish between IPv4 and IPv6 
//  a bit of a hack, but delete(/) will never succeed and ensures   that the same semantics are maintained 
//  Everything is a go, simply start counting the ticks   WARNING: I couldn't find any wait statement on a synchronized   block that would be notified by this notifyAll() call, so   I commented it out  synchronized (this) {      notifyAll();  }   We ping twice a tick, so we only update the tick every other 
//  TODO(ivmaykov): Not sure if cnxn can be null here. It becomes null if channelInactive()   or exceptionCaught() trigger, but it's unclear to me if userEventTriggered() can run   after either of those. Check for null just to be safe ... 
//  could not create tmp directory to hold JAAS conf file : test will   fail now. 
//  FIXME this test is Assert.failing due to client close race condition fixing in separate patch for ZOOKEEPER-63      /**       * this test checks to see if the sessionid that was created for the       * first zookeeper client can be reused for the second one immidiately       * after the first client closes and the new client resues them.       * @throws IOException       * @throws InterruptedException       * @throws KeeperException       */ 
//  TODO: need to tune the default value of thread size 
//  TODO refactor QuorumBase to be special case of this 
//  This might not be 100% right, but it's only used for printing   connection info in the netty implementation so it's probably ok. 
//  Problem 2: Before fix, after session close the ephemeral node   was not getting deleted. But now after the fix after session close 
/*          * Observer should write to disk, so that the it won't request         * too old txn from the leader which may lead to getting an entire         * snapshot.         *         * However, this may degrade performance as it has to write to disk         * and do periodic snapshot which may double the memory requirements          */
/*          * Occasionally seen false negatives with a 5s timeout.          */
//  TODO - investigate why reconfig makes qps null. 
//  TODO: if zks.processPacket() is changed to take a ByteBuffer[],   we could implement zero-copy queueing. 
//  Note that this performance assumption might not hold true for architectures other than x86_64. 
//  Note: the new buffer size is a hint and socket implementation   is free to ignore it, so we don't verify that we get back the   same value. 
// TODO should this be synchronized? 
// TODO: use a factory rather than a switch 
//  XXX No need to do anything 
//  Session has not been re-validated ! 
//  It is sad that isro and srvr are used by ZooKeeper itself. Need fix this   before deprecating 4lw. 
//  TODO we need to figure out the security requirement for this! 
//  Problem 1: Follower had one extra ephemeral node /e1 
//  TODO: in the future, serverId should be validated for all cases, not just the extendedEphemeralTypesEnabled case   TODO: however, for now, it would be too disruptive 
/*              * Since requests are processed in order, we better get a response             * to the first request!              */
//  this is ugly, you have a better way speak up 
//  An authentication error occurred during authentication with the Zookeeper Server. 
/*  TODO: (br33d) we should either put a ConcurrentHashMap on restore()             *       or use Map on save()  */
//  TODO: this doesn't use a quorum verifier 
/*  a mocked ZK class that doesn't do client-side verification     * before/after calling removeWatches  */
//  this shouldn't be necessary (wrapping data with string)   but without it there are problems on the server - ie it   hangs for 30 seconds and doesn't get the data.   TODO investigate 
//  Try to provide hints to use about what went wrong so they can fix their configuration.   TODO: introspect about e: look for GSS information. 
// FIXME: I don't want to have to serialize it here and then         immediately deserialize in next processor. But I'm         not sure how else to get the txn stored into our list. 
// ////////////////   these internal classes are public, but should not generally be referenced. 
//  FIXME: IPv6 is not supported. Using something like Guava's HostAndPort          parser would be good. 
//  this is really a programmatic error and not something that can   happen at runtime 
//  We add backwards since we are pushing into the front   Only send if there's a pending watch   TODO: here we have the only remaining use of zooKeeper in   this class. It's to be eliminated! 
//  TODO: Rather than checking a disjunction here, should be a single member   variable or method in this class to determine whether the client is   configured to use SASL. (see also ZOOKEEPER-1455). 
//  TODO: maybe we should flush in the loop above every N packets/bytes?   But, how do we determine the right value for N ... 
//  Uh oh.  We need to upgrade before we can proceed. 
//  TODO: exit server at this point(?) 
//  only make a copy if this thread isn't already holding a lock 
//  Multiple bad arguments 
//  XXX this doesn't need to be volatile! (Should probably be final) 
//  test will still fail even though we just log/ignore 
//  FIXME ignore for now 
//  XXX We really should NOT need this!!!! 
//  XXX hack 
//  not sure about 3rd arg..what is it? 
// FIXME: need way to more cleanly serialize/deserialize exceptions 
//  small chance that an unexpected message was delivered    after this check, but we would catch that next time 
//  Warning: this will reset the x509Util 
//  a little hacky way to detect key type, but it works 
/*              * The following sequence of code is stupid! You would think that             * only sock.close() is needed, but alas, it doesn't work that way.             * If you just do sock.close() there are cases where the socket             * doesn't actually close...              */
//  todo not every tmp directory needs this file 
//  XXX This shouldn't be needed, but just in case 
/*  * A bunch of constants. * TODO: will get rid of it eventually.  */
//  TODO: can not name this method getState since Thread.getState()   already exists   It would be cleaner to make class SendThread an implementation of   Runnable 
//  handle below: might be harmless if the user doesn't intend to use JAAS authentication. 
//  Should never call this: SASL authentication is negotiated at session initiation.   TODO: consider substituting current implementation of direct ClientCnxn manipulation with   a call to this method (SASLAuthenticationProvider:handleAuthentication()) at session initiation. 
//  Note, we may exceed our max length by a bit when we add the last   watch in the batch. This isn't ideal, but it makes the code simpler. 
//  Make the snapshot directory read only 
//  Ensure that we can convert all valid integers to EventTypes 
/*  notify the client the session is closing and close/cleanup socket  */
//  shutdown previous zookeeper 
/*          * (non-Javadoc)         *          * @see javax.swing.tree.TreeNode#children()          */
/*      * Converting an observer into a participant may sometimes fail with a     * NewConfigNoQuorum exception. This test-case demonstrates the scenario.     * Current configuration is (A, B, C, D), where A, B and C are participant     * and D is an observer. Suppose that B has crashed (or never booted). If a     * reconfiguration is submitted where D is said to become a participant, it     * will fail with NewConfigNoQuorum since in this configuration, a majority     * of voters in the new configuration (any 3 voters), must be connected and     * up-to-date with the leader. An observer cannot acknowledge the history     * prefix sent during reconfiguration, and therefore it does not count towards     * these 3 required servers and the reconfiguration will be aborted. In case     * this happens, a client can achieve the same task by two reconfig commands:     * first invoke a reconfig to remove D from the configuration and then invoke a     * second command to add it back as a participant (follower). During the     * intermediate state D is a non-voting follower and can ACK the state     * transfer performed during the second reconfig command.      */
//  register most recent relogin attempt 
//  Check if client's current server is in the new list of servers 
//  read txnlog but this should be sufficient 
/*                  * Avoids running finish() twice.                  */
//  truncate the log 
/*          * Address of sender          */
//  We need to log the stuff that came in between the snapshot and the uptodate 
//  property is set to an valid int, we should get the set value 
//  If notification > current, replace and send messages out 
//  check for differences 
//  the clients may or may not have already reconnected   to the recovered cluster, force a check, but ignore 
//  zks cannot be null otherwise we would not have gotten here! 
//  check leader running status 
//  reconnect with the same session id 
//  delete the node in the trie.   we need to update the trie as well 
//  or diff 
//  10.10.10.4:1238, 10.10.10.3:1237, 10.10.10.2:1236 
//  lets assert that the first election is the leader 
//  for a dead peer                  
//  If a null Stat object is passed the create should still   succeed, but no Stat info will be returned. 
//  ignore connection loss 
//  Filter out the extra ENTRY_CREATE events that are   sometimes seen at the start. Even though we create the watcher   after the file exists, sometimes we still get a create event. 
//  connect to one of them 
//  Otherwise start worker threads to receive data. 
//  sets quorum sasl authentication configurations 
//  request.hdr is set for write requests, which are the only ones 
//  ensure thread is started once and only once 
//  Write the truststore 
//  This configuration section 'MyZookeeperClient', is missing from the JAAS configuration.   As a result, SASL authentication should fail, which is tested by this test (testAuth()).
//  find the last snapshot 
//  We didn't find \n, read the whole buffer into string buffer 
//  LocalPeerBean 
/*      * Listener thread      */
//  /e is unset, its acl should remain the same. 
//  good, expected that 
/*  The current vote for the leader. Initially me!  */
//  Oh well, never mind 
//  Width of the toster 
//  Verify lastProcessedZxid is set correctly 
//  By default, disable starting a JettyAdminServer in tests to avoid   accidentally attempting to start multiple admin servers on the 
/*                      * If the peer has done enough rounds, then consider joining. The thread                     * will only join if it is part of a quorum supporting the current                      * leader. Otherwise it will try again.                      */
/*  password is test  */
//  add watcher for each node and add node to collection of   watched nodes 
//  generate new config string 
//  do nothing special - stay with the current server 
//  Session has been re-validated 
//  exactly as it is now, except for role change 
//  make sure the watch is removed when the connection closed 
//  1. start up server and wait for leader election to finish 
//  Since SASL authentication has completed (if client is configured to do so),   outgoing packets waiting in the outgoingQueue can now be sent. 
//  objects holding a reference to this object. 
//  Handle situation of clientSection's being null: it might simply because the client does not intend to    use SASL, so not necessarily an error. 
//  Make sure the settings applied above before the socket was potentially upgraded to   TLS still apply. 
//  after restart 
//  Set the factor to high value so that this test case always   resync using txnlog 
//  Trying to load a PEM file with JKS loader should fail 
//  ok 
//  close the input stream 
//  lets wait for any previous leaders to die and one of our new   nodes to become the new leader 
//  do nothing. 
//  add the last logfile that is less than the zxid 
/*  If we've already failed one of the ops, don't bother                     * trying the rest as we know it's going to fail and it                     * would be confusing in the logfiles.                      */
//  waiting for child watchers to be notified 
//  ensure server started, give enough time, so that new leader election 
/*          * Proposed leader          */
//  snapshot files in snap dir 
//  If session has not been validated, there must be NO watches 
//  NO-OP. Adding a packet will already wake up a netty connection   so we don't need to add a dummy packet to the queue to trigger   a wake-up. 
//  expected behavior 
//  this addr won't even be used since we fake the Socket.connect 
//  protocolVersion 
//  Second address doesn't work, so we don't call onConnected() this time   StaticHostProvider should try to re-resolve the address in this case
/*              * Loop in which we exchange notifications until we find a leader              */
//  skip superhammer and clientcleanup as they are too expensive for quorum 
// avoid using literal IP address when security check fails 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.gui.nodeviewer.ZooInspectorNodeViewer#     * nodeSelectionChanged(java.util.Set)      */
/*      * Pending sync requests      */
//  separate patch. 
// Updating version solves conflict -- order matters 
//  Creates principals in the KDC and adds them to a keytab file. 
//  If the client is asking to close the session then   mark as closing 
//  verify ClientCnxnSocketNetty creation 
//  After leader election, lastProcessedZxid will point to new epoch 
//  prepare for next test 
//  small chance that an unexpected message was delivered    after this check, but we would catch that next time    we check events 
//  Make delete fo fail, then verify cversion.   this doesn't happen anymore, we only set the cversion on create   LOG.info("Attempting to delete " + "/test/" + (count + 1));   doOp(logFile, OpCode.delete, "/test/" + (count + 1), dt, zk); 
//  Get default cipher suites from JDK 
//  not necessary to repeat this, expensive and not chroot related
//  inject problem in leader 
//  During startup of thread, thread name will be overridden to 
/*      * Make sure to pass an explicit Watcher because we could be sharing this     * zooKeeper instance with someone else.      */
//  make sure tostring works in both cases 
//  Deleting child using chRoot client. 
/*      * Tests that a conditional reconfig fails if the specified version doesn't correspond     * to the version of the current config.      */
/*          * ZOOKEEPER-1324. the leader sends the new config it must complete         *  to others inside a NEWLEADER message (see LearnerHandler where         *  the NEWLEADER message is constructed), and once it has enough         *  acks we must execute the following code so that it applies the         *  config to itself.          */
//  close connection 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.NodeListener#processEvent(java     * .lang.String, java.lang.String, java.util.Map)      */
/*                  * Processing committedRequests: check and see if the commit                 * came in for the pending request. We can only commit a                 * request when there is no other request being processed.                  */
//  accounted for 
//  ignore this one 
//  Zookeeper client: get username and password from JAAS conf (only used if using DIGEST-MD5). 
//  Packet of death! 
//  these tests are serial, we can speed up InterruptedException 
//  Add multiple child watches 
//  ..but still in progress, because there is a final SASL   message from server which must be received. 
//  watch for everyone to die 
// close the socket to make sure the  other side can see it being close 
//  Test that when we ask for recent snaps we get the number we asked for and 
//  from local session 
//  Unique identifier for each znode that we create. 
//  Follower is within commitLog range 
//  Strip off the surrounding quotes 
//  Global sessions handled on the leader; this call is a no-op if   not tracked as a local session so safe to call in both cases. 
//  were able to talk to the ensemble 
//  now lets kill the leader 
//  ignore duplicate create 
//  Since for each snapshot we have a log file with same zxid, expect same # logs as snaps to be kept 
//  should never be null but just to make   findbugs happy 
/*                      * When we call put later, if the directBuffer is to                     * small to hold everything, nothing will be copied,                     * so we've got to slice the buffer if it's too big.                      */
//  Stop selecting this key while processing on its   connection 
//  and restart leader election if config changed. 
//  send out the kill signal 
//  Propose /foo1 update 
//  min is higher   max is lower 
//  3. SendThread has not created the authenticating object yet, 
//  than 3. 
//  Command line args non-null.  Run what was passed. 
//  First, filter out votes from unheard-from machines. Then   make the views consistent. Sometimes peers will have 
//  Make sure the vote is reset to -1 after shutdown. 
//  we run through 100 snapshots (not all of them)   if we cannot get it running within 100 snapshots   we should  give up 
//  Verify the data in the first transaction 
//  In the DIFF case we don't need to do a snapshot because the transactions will sync on top of any existing snapshot   For SNAP and TRUNC the snapshot is needed to save that history 
//  this will cause everything to shutdown on   this learner handler and will help notify   the learner/observer instantaneously
//  there is only server in the quorum -- run as standalone 
//  Don't log an error for shutdown.
//  assuming that a version uniquely identifies a configuration, so if   version is the same, nothing to do here. 
//  third party customized getAppConfigurationEntry could throw IllegalArgumentException when JAAS   configuration isn't set. We can reevaluate whether to catch RuntimeException instead when more    different types of RuntimeException found 
//  Number of machines stayed the same, my server is not in the new 
//  skip the proposals the peer already has 
//  for Learner): 
//  Wait for request completion infinitely 
//  Id 
//  see ZOOKEEPER-3320 for more details 
// no candidate acked p, return the best candidate found so far 
//  "Connection reset by peer" 
//  convert from a server path to a client path 
//  The first time we are configured, it is just to tell   us which machine we are 
//  parts[i] == "host:leaderPort:leaderElectionPort;clientPort" 
//  does not send anything back when it is done. 
//  Convert windows path to UNIX to avoid problems with "\" 
//  reconfigMode = false (next shouldn't return null). 
//  closing so this is expected 
//  Watch status of ZooKeeper server. It will do a graceful shutdown 
//  lets start servers 2, 3, 4 with the new config 
//  remove hosts number 6 and 7 (the currently last two in the list) 
/*      * This is a simple test - try to connect two clients to a server     * accepting a maximum of one connection from each address. Check that     * only one is accepted. Close that connection, and check that the other     * eventually connects.     *     * There is a possibility of a false positive here, as when zk2 is tested     * for having connected it might not have been given enough time, and finish     * connecting after the test is done. Since the     * server doesn't tell the client why it hasn't connected, there's no     * obvious way to detect the difference.      */
/*      * (non-Javadoc)     *     * @see org.apache.zookeeper.server.ServerCnxnIface#getSessionTimeout()      */
//  Only the root path can end in a /, so strip it off every other prefix 
//  this server wasn't around during the configuration change   we should check that it is able to connect, finds out   about the change and becomes an observer. 
//  At this point, there might still be new packets appended to outgoingQueue. 
/*              * We no longer process NEWLEADER ack with this method. However,             * the learner sends an ack back to the leader after it gets             * UPTODATE, so we just ignore the message.              */
/*         * I'm done so joining.         */
//  Disable receiving data for all open connections ... 
//  important for x-DC scenarios. 
//  now make environment for client hang 
//  servers from the old list that appear in the new list 
//  simulate log file 
//  Zxids should always be in order for write requests 
//  indicates that a reconfig just committed 
//  Start up a new instance 
//  Check that all clients connect properly 
//  If preAllocSize is positive and we are within 4KB of the known end of the file calculate a new file size 
//  determine client principal from subject. 
//  superuser: use Java system property for password, if available. 
//  'B' 
//  consider as error
// good, wanted to see that, let's make sure we ran out of time 
//  create transactions to create the snapshot with create/delete pattern 
//  Construct a ConcurrentHashSet using a ConcurrentHashMap 
// 	    t3.start(); 
//  Should not happen, because we check for IPv6 address above 
// Let's make sure that we hit the code that ran the real assertion above 
//  together like in testNextGoesRound() 
//  The synchronized block here is for two purpose:   1. synchronize with the final cleanup() in SendThread.run() to avoid race   2. synchronized against each packet. So if a closeSession packet is added, 
//   "modprinc -maxlife 3mins <principal>" in kadmin. 
//  got results 
//  verify super with correct pass success 
//  cool this is what we want 
//  continuation 
//  Node 1 must be started first, before quorum is formed, to trigger the attempted invalid connection to 3 
//  Initialize with null vote 
//  Send back the ping with our session data 
//  We send DIFF to (6,0) and forward any packet starting at (4,1) 
/*      * ZOOKEEPER-2201 - OutputArchive.writeRecord can block for long periods of     * time, we must call it outside of the node lock.     * We call tree.serialize, which calls our modified writeRecord method that     * blocks until it can verify that a separate thread can lock the DataNode     * currently being written, i.e. that DataTree.serializeNode does not hold     * the DataNode lock while calling OutputArchive.writeRecord.      */
//  check to see if this user is in the user password database. 
//  during the tests we run with 100K prealloc in the logs.   on windows systems prealloc of 64M was seen to take ~15seconds   resulting in test Assert.failure (client timeout on first session).   set env and directly in order to handle static init/gc issues 
//  start two servers to form a quorum; client should detect this and 
//  we don't have an option specified.   just delete whole quota node 
/*          * We return true if one of the following three cases hold:         * 1- New epoch is higher         * 2- New epoch is the same as current epoch, but new zxid is higher         * 3- New epoch is the same as current epoch, new zxid is the same         *  as current zxid, but server id is higher.          */
// need to get the PID number of the process first 
//  Propose an update 
// Delete the leaves first and eventually get rid of the root  Delete all versions of the node with -1. 
//  child channels options 
//  ok lets find the leader and kill everything else, we have a few 
//  Prior to ZOOKEEPER-2249, attempting to pad in association with the second transaction will corrupt the first 
//  ensure no late arrivals 
//  count down to avoid infinite blocking call due to this latch, if   any. 
//  ignoring the interrupt 
// 3. Upgrade peer0,1,2 with quorum.auth.enableSasl=true and 
//  be propagated to the other servers in the ensemble. 
//  property is set but with white spaces 
//  generate old config string 
//  Authentication exchange has completed 
// server.# 
//  Create read-only server but don't start it immediately 
// Each op in a multi-op must have the same zxid! 
/*          * Write id (3.4.6 protocol). This previously caused a NPE in         * QuorumCnxManager.          */
/*         * Lists what threads haven't joined. A thread doesn't join if        * it hasn't decided upon a leader yet. It can happen that a        * peer is slow or disconnected, and it can take longer to        * nominate and connect to the current leader.         */
/*      * For ZOOKEEPER-1732 verify that it is possible to join an ensemble with     * inconsistent election round information.      */
/*          * if local session is not enabled or it used to be our local session         * throw sessions expires          */
//  things needed for waitForEpochAck to run (usually in leader.lead(), but we're not running leader here) 
//  same configs, and they should be equal to the config we get from QuorumPeer. 
//  Start sending packets 
//  before create otw race 
//  determined by whether we are currently throttled or not 
/*  Does it start with an IPv6 literal?  */
//  of expiring the session. 
//  don't call setup - we don't want to reassign ports/dirs, etc... 
//  If the thread is in the the grace period, interrupt   to come out of waiting. 
//  ... and close connection 
//  verify no auth 
// Expected 
//  shut the leader down 
// in milliseconds, socket should connect/read within this period otherwise SocketTimeoutException 
//  LOG.warn("Proposed leader: " +   proposedLeader); 
//  When it comes to this point, it guarantees that later queued   packet to outgoingQueue will be notified of death. 
//  get leader 
//  Verify that we have at least NUM_MESSAGES / SNAPCOUNT txnlog 
//  standalone starts with 0 epoch while quorum starts with 1 
/*                              * Try to obtain a challenge only if does not have                             * one yet                              */
/*          * (non-Javadoc)         *          * @see javax.swing.tree.TreeNode#getParent()          */
//  Now we're adding it back as a participant and everything should work. 
//  Handle race condition where a node is listed   but gets deleted before it can be queried   ignore 
//  load the epochs 
//  resolve() call keeps the size of provider 
/*      * returns the string that maps to this stat tracking.      */
//  In the tests below, a "Strict" server means a UnifiedServerSocket that   does not allow plaintext connections (in other words, it's SSL-only).   A "Non Strict" server means a UnifiedServerSocket that allows both   plaintext and SSL incoming connections. 
//  If we get notified about possibly missed events, reload the key store / trust store just to be sure. 
//  NOP 
//  modify server's client port 
//  Receive challenge and store somewhere else 
//  Test that the path string is validated 
//  Set the margin 
//  2: inject network problem in one of the follower 
//  This is the "auth" id, so we have to expand it to the   authenticated ids of the requestor 
//  processResult() is used by ClientCnxn's sendThread to respond to   data[] contains the Zookeeper Server's SASL token.   ctx is the ZooKeeperSaslClient object. We use this object's respondToServer() method   to reply to the Zookeeper Server's SASL token 
//  Now we just start watching the assignments directory 
//  try to delete it now as we have done with the created file, why to   wait for deleteOnExit() deletion 
//  Leader.NEWLEADER 
//  8. check the node exist in previous leader but not others 
//  start with the initLimit, once the ack is processed   in LearnerHandler switch to the syncLimit 
//  Watcher function doesn't exists for the specified params 
//  See ZOOKEEPER-1161 for more details 
//  Divide the new servers into oldServers that were in the previous list 
/*              * Higher id              */
//  EventWatch is a simple, immutable type, so all we need to do   is make sure we can create all possible combinations of values. 
//  kill anything that was removed for the children 
//  Let the notifications timeout 
//  success 
//  test that all servers have: 
//  Force leader to use snapshot to sync with follower 
// No quorum in new config (1/2) 
//  If p is a reconfiguration, multiple other operations may be ready to be committed,   since operations wait for different sets of acks.   Currently we only permit one outstanding reconfiguration at a time   such that the reconfiguration and subsequent outstanding ops proposed while the reconfig is   pending all wait for a quorum of old and new config, so its not possible to get enough acks   for an operation without getting enough acks for preceding ops. But in the future if multiple   concurrent reconfigs are allowed, this can happen and then we need to check whether some pending   ops may already have enough acks and can be committed, which is what this code does. 
// LOG.info("Defaulting to majority quorums"); 
//  When increment ... 
//  Check if we shutdown or doIO() closed this connection 
// Verify tree deleted 
//  used by ClientCnxn to know whether to emit a SASL-related event: either AuthFailed or SaslAuthenticated, 
//  We send SNAP 
//  If there isn't any version associated with the filename,   the default version is 0. 
//  and the stat and quota nodes 
/*  followers in its view                                     */
//  verify that joiner has up-to-date config, including all four servers. 
// //  // If you update the configuration parameters be sure  // to update the "conf" 4letter word  // 
//  ignore - can't find the path, will output "n/a" instead 
//  Assert that commands are getting forwarded correctly 
//  is disabled 
//  only previously existing records need to be rolled back. 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.gui.nodeviewer.ZooInspectorNodeViewer#     * getTitle()      */
//  Number of machines becomes smaller, my server is in the new cluster 
//  Just put the description in 
//  cleanup <path vs watchlist> 
//  Test that when asking for more snaps than we created, we still only get snaps 
//  Only include votes from machines that we heard from 
//  Integer representation of value 
//  1 day 
//  make sure a different leader was elected 
//  Populate DIGEST-MD5 user -> password map with JAAS configuration entries from the "QuorumServer" section.   Usernames are distinguished from other options by prefixing the username with a "user_" prefix. 
//  r[0] == "host:clientPort"   r[1] == "host:leaderPort:leaderElectionPort"   Appending ";clientPort" 
//  we do this in an attempt to ensure that not all of the servers   in the ensemble take a snapshot at the same time 
//  Since this is already a committed proposal, we need to follow 
//  required for compilation from C++ 
/*      * Mapping from Peer to Thread number      */
//  eof reached 
//  not a directory 
//  Don't expect to get the same stats for different creates. 
//  When reset ... 
//  Client-initiated renegotiation in TLS is unsafe and   allows MITM attacks, so we should disable it unless   it was explicitly enabled by the user.   A brief summary of the issue can be found at   https://www.ietf.org/proceedings/76/slides/tls-7.pdf 
//  Make space for length 
//  Peer has zxid in txnlog range 
//  check watches 
//  element could be removed by poll() 
//  that is rather innocuous. 
//  Log warning message if txn comes out-of-order 
//  reset acl (back to open) and verify accessible again 
/*                      * The leader executes the following block, which essentially shuts down                     * the peer if it is not the last round.                       */
//  Expiry time is (now/cnxnTimeout + 1)*cnxnTimeout   Range is (now + cnxnTimeout) to (now + 2*cnxnTimeout)   Add 1s buffer to be safe. 
//  currently shouldn't happen since there are only 2 learner types 
//  setup redirect out/err streams to get System.in/err, use this judiciously!   get current err 
//  Only participant need to get outstanding proposals 
// corrupting the data 
//  254 
//  Give things time to report; 
//  if we have a loopback and it has an address use it 
/*                                  * If this server is not looking, but the one that sent the ack                                 * is looking, then send back what it believes to be the leader.                                  */
// find out who is the leader and kill it 
//  port in static config file. 
//  Sketchy: We assume there will be a leader (probably us) in 3 seconds. 
//  Leader asks for epoch (mocking Leader.lead behavior)   First add to connectingFollowers 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorNodeManager#setData     * (java.lang.String, java.lang.String)      */
//  It's all over 
//  Test stat and watch of non existent node 
//  No need to synchronize since cnxns is backed by a ConcurrentHashMap 
//  quorum members 
//  The change should not have happened yet, since we haven't committed 
//  since they can't complete the reconfig 
//  Revocation checking is only supported with the PKIX algorithm 
/*      * This test wouldn't create any dynamic config.     * However, it adds a "clientPort=XXX" in static config file.     * It checks the standard way of standalone mode.      */
//  The stat parameter should be optional. 
/*  Create  */
//  if the weights are not above zero, things will get messed up 
//  Try to load a non-protected private key while providing a password 
/*          * Since Configuration initializes the key store and trust store related         * configuration from system property. Reading property from         * configuration will be same reading from system property          */
//  not able to truncate the log 
//  No more packets to send: turn off write interest flag.   Will be turned on later by a later call to enableWrite(),   from within ZooKeeperSaslClient (if client is configured   to attempt SASL authentication), or in either doIO() or   in doTransport() if not. 
//  If we're testing a follower, also check the session id on the 
//  I'm not in the view 
//  perhaps this is a V0 Create 
//  Since this is a rough sanity check, add some padding to maxBuffer to   make up for extra fields, etc. (otherwise e.g. clients may be able to   write buffers larger than we can read from disk!) 
//  Submit request directly to leader 
//  add the n recent snap files for assertion 
//  Update lastCommitted and Db's zxid to a value representing the new epoch 
//  this is an unlikely edge case, but check it just in case 
//  verify ClientCnxnSocketNIO creation 
//  since we have already acked an epoch equal to the leaders, we cannot ack   again, but we still need to send our lastZxid to the leader so that we can   sync with it if it does assume leadership of the epoch.   the -1 indicates that this reply should not count as an ack for the new epoch 
//  Here we create 3000 znodes 
//  Start the servers with a static config file, without a dynamic config file. 
//  This tests the case where ZK ensemble does not have the super user's password configured.   Reconfig should fail as the super user has to be explicitly configured via   zookeeper.DigestAuthenticationProvider.superDigest. 
//  Cut the connection, so the server will create closeSession as part 
//  Send diff when we see the follower's zxid in our history 
//  Peer has zxid (3, 1) 
//  Now check that other commands don't blow everything up 
//  RFC 2818, 3.1. Server Identity   "...Names may contain the wildcard   character * which is considered to match any single domain name   component or component fragment..."   Based on this statement presuming only singular wildcard is legal 
//  found path watcher 
//  we'll catch this later if it does happen after timeout, so   why waste the time on poll
//  override the defaults 
//  before expiration). 
//  determine how long to sleep from looking at ticket's expiry.   We should not allow the ticket to expire, but we should take into consideration   MIN_TIME_BEFORE_RELOGIN. Will not sleep less than MIN_TIME_BEFORE_RELOGIN, unless doing so   would cause ticket expiration. 
//  This is a relatively common exception that we can't avoid 
//  null StoreFileType means 'autodetect from file extension' 
//  When local flag is true, remove watchers for the given path   irrespective of rc. Otherwise shouldn't remove watchers locally   when sees failure from server. 
//  Queue up any outstanding requests enabling the receipt of   new requests 
//  (this is twice the timeout used in Leader#getEpochToPropose) 
//  Make create to fail, then verify cversion. 
//  n recent snap shots 
/*  Sequence numbers for messages  */
//  is also auth enabled while enabling quorum server require sasl. 
// clear up the kerberos state. But the tokens are not cleared! As per  the Java kerberos login module code, only the kerberos credentials 
//  if this is not in cnxns then it's already closed 
//  if \n is first char in buffer, leave the string buffer empty 
//  wait for new servers to be up running 
//  check and make sure the change is persisted 
//  verify super can do anything and ignores ACLs 
/*                              * Do nothing, just try again                              */
//  Round-robin assign this connection to a selector thread 
//  Warn about inconsistent peer type 
//  Text area for the message 
/*          * Start mock server 2          */
/*                                  * Global variable keeping track of                                  * how many peers have successfully                                  * joined.                                  */
/*  set socket linger to false, so that socket close does not block  */
//  clear the buf so we don't get something we read before we sought   number of entries skipped to get to the end of the iterator, less the number skipped to get to the start 
/*  Test that the majority quorum verifier only counts votes from  */
//  Use BufferedOutputStream to reduce the number of IP packets. This is 
//  the new server's config is going to include itself and the current leader 
//  verify that the truncation and subsequent append were processed 
//  client login 
//  We take advantage of the limited size of the length to look   for cmds. They are all 4-bytes which fits inside of an int 
//  add previously existing records back. 
//  now that the ack has been processed expect the syncLimit 
/*      * Determine how much time a process has to wait once it believes that it     * has reached the end of leader election.      */
//  if this Assert.fails it means we are not cleaning up after the closed   sessions. 
//  We might consider changing the processor behaviour of    Observers to, for example, remove the disk sync requirements.   Currently, they behave almost exactly the same as followers. 
//  The available port range that we use stays away from the ephemeral port   range, which the OS will assign to client socket connections.  We can't   coordinate with the OS on the assignment of those ports, so it's best to   stay out of that range to avoid conflicts.  Typical ranges for ephemeral   ports are:   - IANA suggests 49152 - 65535   - Linux typically uses 32768 - 61000   - FreeBSD modern versions typically use the IANA suggested range   - Windows modern versions typically use the IANA suggested range 
//  check for more than 2 children --   if zookeeper_stats and zookeeper_qutoas   are not the children then this path   is an ancestor of some path that 
/*      * (non-Javadoc)     *      * @see     * javax.swing.event.ListSelectionListener#valueChanged(javax.swing.event     * .ListSelectionEvent)      */
//  Generate transaction so we will have some txnlog 
//  Each session should see its cxids in order 
//  let qpconfig parse the file and then pull the stuff we are   interested in 
//  Look through the logs for output that indicates the falseLeader is LEADING, then LOOKING, then FOLLOWING 
//  in general we will see 1 connection from each   host, setting the initial cap to 2 allows us   to minimize mem usage in the common case   of 1 entry --  we need to set the initial cap   to 2 to avoid rehash when the first entry is added 
//  We use the order array to preserve the order of the commands   for help. The hashmap will not preserver order. (It may be overkill.) 
//  DIFF only 
/*  String subreport = reads + " "                                + (((double) rlatency) / reads) + " " + writes                                + " " + (((double) wlatency / writes));  */
//  Try creating some data. 
/*  * <p> * Abstraction that interprets the <code>ephemeralOwner</code> field of a ZNode. Originally, * the ephemeralOwner noted that a ZNode is ephemeral and which session created the node. * Through an optional system property (<code>zookeeper.extendedTypesEnabled</code>) "extended" * features such as TTL Nodes can be enabled. Special bits of the ephemeralOwner are used to * denote which feature is enabled and the remaining bits of the ephemeralOwner are feature * specific. * </p> * <p> * <p> * When the system property <code>zookeeper.extendedTypesEnabled</code> is true, extended types * are enabled. An extended ephemeralOwner is defined as an ephemeralOwner whose high 8 bits are * set (<code>0xff00000000000000L</code>). The two bytes that follow the high 8 bits are * used to denote which extended feature the ephemeralOwner represents. The remaining 5 bytes are * used by the feature for whatever purpose is needed * </p> * <p> * <p> * Currently, the only extended feature is TTL Nodes. It is denoted by the extended feature value of 0. * i.e. for TTL Nodes, the ephemeralOwner has the high byte set to 0xff and the next 2 bytes are 0 followed * by 5 bytes that represent the TTL value in milliseconds. So, an ephemeralOwner with a TTL value of 1 * millisecond is: <code>0xff00000000000001</code>. * </p> * <p> * <p> * To add new extended features: a) Add a new name to the enum, b) define a constant EXTENDED_BIT_XXXX that's next * in line (after TTLs, that would be <code>0x0001</code>), c) add a mapping to the extendedFeatureMap via the static * initializer * </p> * <p> * <p> * NOTE: "Container" nodes technically are extended types but as it was implemented before this feature they are * denoted specially. An ephemeral owner with only the high bit set (<code>0x8000000000000000L</code>) is by definition * a container node (irrespective of whether or not extended types are enabled). * </p>  */
/*  null StoreFileType means 'autodetect from file extension'  */
//  Recovery mode 
//  For backward compatibility test, some tests create dynamic configuration   without setting client port. 
//  ZOOKEEPER-2693 disables all 4lw by default. 
// reconfigure out leader and follower 1. Remaining follower 
//  and newServers that were not in the previous list 
//  zkServer has been started. So we don't need to start it again in secureCnxnFactory. 
//  Keep track of the latest zxid which already queued 
//  clear data structures used for auth 
//  Client is configured to use a valid login Configuration, so   authentication is either in progress, successful, or failed. 
//  check 
// The old port should be clear at this stage 
//  enable it if disabled 
//  Unlike with Krb5LoginModule, we don't do any actual login or credential passing here: authentication to Zookeeper   is done later, through the SASLClient object. 
//  The synchronized is to prevent the race on shared variable "sslEngine".   Basically we only need to create it once. 
//  Bring it back 
//  Do trigger an event to make sure that we do not get 
//  create session with min value 
//  Peer has newer zxid 
//  Height of the toster 
/*  we are going to say we last acked epoch 20  */
//  setup channel, variables, connection, etc. 
//  ZOOKEEPER-569:   If no votes are received for live peers, reset to voting    for ourselves as otherwise we may hang on to a vote  
//  this lock guarantees that channel won't be assigned after cleanup(). 
//  interval. 
//  maintain semantics even in chroot case   specifically - root cannot be deleted   I think this makes sense even in chroot case. 
//  pzxid updated with deleteNode on higher zxid 
//  make sure the leader has the subsequent changes that were made while it was offline 
//  Validate that we don't see any txn from the first session 
//  If not null then shutdown this leader 
// leader election time, unless the designated leader fails                              
//  CommmitedLog is empty, we will use txnlog up to lastProcessZxid 
//  Kill server 1 to avoid it interferences with FLE of the quorum {2, 3, 4}. 
//  let's be conservative on the typical number of children 
//  We take advantage of the limited size of the length to look 
//  The create will trigger the get children and the exist   watches 
//  There should be 2000 create requests 
//  only take in the first 3 servers as old quorum config. 
/*  Delete of a node folowed by an update of the (now) deleted node  */
//  Convert WatchedEvent to a type that can be sent over the wire 
//  throws a LoginException: see startConnect() below. 
//  send 0 if session is no 
//  This method gets the version from the end of dynamic file name.   For example, "zoo.cfg.dynamic.0" returns initial version "0".   "zoo.cfg.dynamic.1001" returns version of hex number "0x1001".   If a dynamic file name doesn't have any version at the end of file, 
//  Verify each quorum peer has expected config in its config zNode. 
//  returns all configuration servers -- participants and observers 
//  first convert participant to observer, then observer to participant, 
//  convince falseLeader that it is the leader 
/*  version - version of config from which we want to reconfigure - if current config is different     * reconfiguration will fail. Should be committed from the CLI to disable this option.      */
//  Update the node on the leader 
// check for the code path that throws at server 
//  Number of machines increases, my server is not in the new cluster   load on old servers must be decreased, so must connect to one of the   new servers   i.e., pNew = 1. 
//  set watches on child 
//  take a snapshot 
//  65537 
//  We have the request, now process and setup for next 
//  512k 
//  check that static config file doesn't include membership info   and has a pointer to the dynamic configuration file 
//  Fallthrough and log errors outside the synchronized block 
//  we are going to have to extrapolate the epoch information 
//  best effort to print the path assoc with this request 
//  and close the connection to the leader 
// if neither option -n or -b is specified, we delete   the quota node for thsi node. 
//  shutdown() has to be explicitly called for every thread to   make sure that resources are freed properly and all fixed network ports   are available for other test cases 
//  we are now going to start getting transactions to apply followed by an UPTODATE 
/*      * (non-Javadoc)     *      * @see     * javax.swing.event.TreeSelectionListener#valueChanged(javax.swing.event     * .TreeSelectionEvent)      */
//  hdm.addLoggerMBean(logger.getName()); 
//  2 followers out of 3 are a majority of the voting view 
//  its supposed to be the first server on serverList.   we'll set it later, see below (*) 
//  config file. 
//  don't overwrite with "special" xids - we're interested   in the clients last real operation 
/* election port */
/*                 cversion > 0: keep newly created containers from being deleted                before any children have been added. If you were to create the                container just before a container cleaning period the container                would be immediately be deleted.              */
//  interesting to see what's there... 
//  During session upgrade 
//  Construct a connection request 
//  create a /test znode and check that read/write works before 
//  Next the old servers 
//  during second iteration leavingIndex will be the index of the leader 
/*  password is 'test' */
//  org.apache.log4j.LogManager.getLoggerRepository(); 
//  Make sure nothing is straggling! 
/* quorum port */
//  Attempting to load with the wrong key password should fail 
//  there can be extra sessionClose proposals 
//  create 5 servers 
//  Trigger the watches and ensure they properly propagate to the client 
/*  4 MB  */
//  Get the string that is being dropped. 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#     * getNodeChild(java.lang.String, int)      */
//  Get memory information. 
//  Make all zxids for a given vote id equal to the largest zxid seen for 
//  use async, otherwise it will block the logLock in   ZKDatabase and the setData request will timeout 
//  10.10.10.2:1236, 10.10.10.1:1235 
//  create ephemeral node 
/*              * We match with nextPending so that we can move to the             * next request when it is committed. We also want to             * use nextPending because it has the cnxn member set             * properly.              */
// set that we have been interrupted. 
/*          * First make the views consistent. Sometimes peers will have different         * zxids for a server depending on timing.          */
//  Verify that FinalRequestProcessor hasn't changed the original ACL objects 
//  first address worked 
//  cause disconnection - this will cause next to be called   which will in turn call nextReconfigMode
//  Try to reduce memory consumption by freeing up buffer space   which is no longer needed. 
//  wait until followers time out in getEpochToPropose - they shouldn't return   normally because the leader didn't execute getEpochToPropose and so its epoch was not 
//  seconds, so it should be plenty of time 
//  add all to commandMap 
//  Assume this is an existing cluster. 
//   we check events 
//  If there is only one createSession request in between, zxid diff   will be exactly 2. The alternative way of checking is to actually 
//  verify all the servers reporting same number of nodes 
//  increase the tick time to delay the leader going to looking 
//  server ids are 1, 2 and 3 
//  However, we should be able to disconnect and reconnect to the same   server with the same session id (as long as we do it quickly 
//  waiting time for expected condition 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#getACLs     * (java.lang.String)      */
/*              * Wait until leader starts up              */
//  6. exit follower A after taking snapshot 
//  the dynamic file pointer. 
//  Append and commit 2 transactions to the log 
/*      * (non-Javadoc)     *      * @see java.lang.Object#hashCode()      */
/*          * (non-Javadoc)         *         * @see org.apache.zookeeper.server.RequestProcessor#processRequest(org.apache.zookeeper.server.Request)          */
//  try sync zk exists  
//  Attempt to renegotiate after establishing the connection 
//  Verify AlwaysOnTop Flag... 
//  Leader and learner will control the zookeeper server and pass it into QuorumPeer. 
//  /foo 
//  We don't want to do this check since the session expiration thread   queues up this operation without being the session owner.   this request is the last of the session so it should be ok  zks.sessionTracker.checkSession(request.sessionId, request.getOwner()); 
//  ok we have some match and need to update 
//  object created but start() not called yet   start() called but background thread has not entered main loop   background thread is running   stop() called but background thread has not exited main loop   stop() called and background thread has exited, or background thread crashed 
//  if it is already simple, just return it 
//  waiting for re-election. 
//  ************** target file does not exist 
//  note that clientToken might be empty (clientToken.length == 0):   if using the DIGEST-MD5 mechanism, clientToken will be empty at the beginning of the   SASL negotiation process. 
// check that membership makes sense; leader will make these checks again  don't check for leader election ports since   client doesn't know what leader election alg is used 
//  we've already validated, therefore if the path is of length 1 it's the root 
// PASS 
//  this replicates NC - close the output stream before reading 
//  No command specified, print links to all commands instead 
//  a session should automatically expire after an amount of time 
//  with 0-padding in the filename 
//  we are the final link in the chain 
//  done checking - it's the root 
//  Set default font... 
/*  leaving - comma separated list of server IDs to be removed from the ensemble. Only used for     * incremental reconfigurations.      */
//  try node creation for around 15 second, 
//  If the user explicitly overrides the default Login Context, they probably expected SASL to   succeed. But if we got here, SASL failed. 
//  Servers have been set up. Now go test if secure connection is successful. 
//  assert remotePeerBean.1 of ReplicatedServer_2 
//  The leader is going to dump the database 
//  for a dead peer 
//  VisibleForTesting 
// login and also update the subject field of this instance to 
/*      * Process a sync request      */
//  However a failure is still expected as user is not authenticated, so ACL check will fail. 
//  Thread.sleep(100);   } 
//  Note that this thread isn't going to be doing anything else,   so rather than spawning another thread, we will just call   run() in this thread. 
// dumpConnections connection is implemented only in NIOServerCnxnFactory 
//  make sure that they timed out and didn't return normally   
//  we don't need to roll back any records because there is nothing left. 
//  & 0xFFFFFFFFL;   >> 32; 
// incremental change - must be a majority quorum system    
//  assert remotePeerBean.1 of ReplicatedServer_3 
//  Exception is set when local session failed to upgrade   so we just need to report the error 
//  Have to check !closingChannel, because an error in   receiveMessage() could have led to close() being called. 
//  -2 is the xid for pings 
//  concurrent reconfigs are allowed, this can happen. 
//  Oldest log is already remove, so this should point to the start of 
//  reconstructing transaction with the chroot prefix 
//  Verify the data in the second transaction 
//  now check if the bytes match the quota 
//  Step for the toaster 
/*              * Higher zxid              */
//  the list is already removed from the ephemerals   so we do not have to worry about synchronizing on   the list. This is only called from FinalRequestProcessor   so there is no need for synchronization. The list is not   changed here. Only create and delete change the list which   are again called from FinalRequestProcessor in sequence. 
/*      * (non-Javadoc)     *      * @see     * javax.swing.event.ChangeListener#stateChanged(javax.swing.event.ChangeEvent     * )      */
//  authentication packet. 
//  This should never happen! 
//  But still, what's valid in white list will get through. 
//  we need to make sure that we don't take the snapshot twice. 
//  if so, I'll remain the leader     
//  or fails. 
//  DIFF + 4 proposals + 4 commit 
//  If the connect attempt was cancelled but succeeded   anyway, make sure to close the channel, otherwise   we may leak a file descriptor. 
//  Reset to MIN_SNAP_RETAIN_COUNT if invalid (less than 3)   PurgeTxnLog.purge(File, File, int) will not allow to purge less 
//  2) verify that empty child name success if sequential  
//  We send TRUNC to 3 and forward any packet starting 5 
//  if node is created successfully then it means that ZooKeeper service 
//  @VisibleForTesting 
//  Throttle acceptance of new requests. If this entailed a state change, 
/*              * Main loop              */
//  This should never happen, but we should fall back to sending   snapshot just in case. 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#     * getSessionMeta()      */
//  Add all the removed watch events to the event queue, so that the   clients will be notified with 'Data/Child WatchRemoved' event type. 
//  The pattern is holding so far.  Let's run the counter a bit   to be sure it continues to spit out the correct answer 
/*          * Creates list of peers.          */
//  Use a single listener instance to reduce GC   Note: this listener is only added when LOG.isTraceEnabled() is true, 
//  last op committed was a leader change - from now on    the new leader should commit         
//  New Watcher which will be used for removal 
//  3: close the session so that ephemeral node is deleted 
//  CN matching has been deprecated by rfc2818 and can be used   as fallback only when no subjectAlts are available 
//  content changed 
//  write extra configurations 
//  During connection expiry the server will close the connection.   After the socket is closed, when the client tries to read a   line of text it will throw java.net.SocketException.   @see jira issue ZOOKEEPER-1862 
//  if session creation Assert.fails dump the thread stack   and try the next server 
//  extract server id x from first part of joiner: server.x 
//  learner with ipaddress in principal 
//  This is expected case since server 0 is down and 3 can't vote   (observer in current role) and we need 3 votes from 0, 1, 2, 3, 
//  remove watcher for each node and remove node from   collection of watched nodes 
//  Create the NIOServerCnxn that will handle the client requests 
//  ok this is the limit node   get the real node and update   the count and the bytes 
// wait for servers to be up 
//  try it again 
//  Set to true when connected to a quorum server. 
//  worst case here the tmp file/resources(fd) are not cleaned up   and the caller will be notified (IOException) 
//  Test child watch and create with sequence 
/*  return a zxid of zero, since we the database is empty  */
//  Start 3rd peer and check if it joins the quorum 
//  Authenticate client certificate 
//  Use setData instead of sync API to force a view update.   Check ZOOKEEPER-2137 for details. 
//  Color for toaster 
//  now check if the counts match the quota 
//  Here we enable the 4lw which ZooKeeper tests depends. 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorManager#     * setLastConnectionProps(java.util.Properties)      */
//  this is the only child node. 
//  make sure it has a chance to write it to disk 
//  Start and schedule the the purge task 
//  Peer is within committedLog range 
// empty logs 
//  Close the client without changing the node 
//  We don't need to worry about removing empty sets,   they'll eventually be removed when they expire. 
//  shouldn't happen without filter 
//  -1 means notification 
//  Kill half the servers, make a change, restart the dead 
/*                  * Sends more notifications if haven't received enough.                 * Otherwise processes new notification.                  */
/*      * Shutdown flag      */
//  Assert 
/*      * getZNodeList and getZNodeListJSON are bogus - but necessary.     * Unfortunately Jersey 1.0.3 is unable to render both xml and json properly     * in the case where a object contains a list/array. It's impossible to get     * it to render properly for both. As a result we need to split into two     * jaxb classes.      */
//  TODO test octet fully 
//  This can happen in state transitions,   just ignore the request 
//  http://docs.oracle.com/javase/6/docs/technotes/guides/security/jgss/jgss-features.html   """   In addition, when performing operations as a particular   Subject, e.g. Subject.doAs(...) or   Subject.doAsPrivileged(...),   the to-be-used GSSCredential should be added to Subject's   private credential set. Otherwise, the GSS operations will   fail since no credential is found.   """ 
//  Local session 
/*                      * Building notification packet to send                      */
//  2 followers out of 5 is not a majority 
//  ignore 
//  do authenticating learner 
//  SASL authentication is completed, successfully or not:   enable the socket's writable flag so that any packets waiting for authentication to complete in 
//  Assert   Resolver called 10 times, because we shouldn't cache the resolved addresses 
//  stat, ruok and isro are white listed. 
//  the response 
//  getting a quorum from all necessary configurations. 
//  ignore for purposes of this test 
//  1. Matches authenticationID and authorizationID 
/*  In the following IF-THEN-ELSE block, we process syncs on the leader.         * If the sync is coming from a follower, then the follower         * handler adds it to syncHandler. Otherwise, if it is a client of         * the leader that issued the sync command, then syncHandler won't         * contain the handler. In this case, we add it to syncHandler, and         * call processRequest on the next processor.          */
//  check for well formed ACLs   This resolves https://issues.apache.org/jira/browse/ZOOKEEPER-1877 
//  make sure everything is consistent 
//  2. kill all followers 
/*      * Class to verify of the thread has become a follower      */
//  Exists only to defeat instantiation. 
//  we should see that now all servers have the same config of 5 servers 
//  possible 
//  Test synchronous API 
//  2nd read is after the renegotiation attempt and will fail 
//  TODO Write the v6addr2Bytes 
//  wait up to 30 seconds for the disco to be delivered 
/*                      * Return message to queue for another attempt later if                     * epoch hasn't changed.                      */
//  if not RSA, assume EC 
/*  This file copied from Hadoop's security branch,  * with the following changes:  * 1. package changed from org.apache.hadoop.security to  *    org.apache.zookeeper.server.auth.  * 2. Usage of Hadoop's Configuration class removed since  *    it is not available in Zookeeper: instead, system property  *    "zookeeper.security.auth_to_local" is used.   */
//  note that we should run the server, shut it down and only then   simulate a reconfig in progress by writing the temp file, but here no   other server is competing with them in FLE, so we can skip this step 
/*      * We populate the necessary data structures in the CommitProcessor     * instance and run processCommitted      */
//  create persistent sequential node 
//  pick a reasonable epoch number   this should only happen once when moving to a   new code version 
//  Set the joining/leaving/members values based on the mode we're in 
/*                  * Processing queuedRequests: Process the next requests until we                 * find one for which we need to wait for a commit. We cannot                 * process a read request while we are processing write request.                  */
/*  * This code is originally from HDFS, see the similarly named file there * in case of bug fixing, history, etc. * * Branch : trunk * Github Revision: 1d1ab587e4e92ce3aea4cb144811f69145cb3b33  */
//  Try to remove follower2, which is the only remaining server. This should fail. 
//  Write to txnlog and take periodic snapshot 
//  This test simulate the use case of change of membership through rolling   restart. For a 3 node ensemble we expand it to a 5 node ensemble, verify   during the process each node has the expected configuration setting pushed   via updating local zoo.cfg file. 
//  validate upper limit 
//  Wait for the listener to terminate. 
//  8. now we have invalid data on disk, let's load it and verify 
//  don't do anything 
//  simply return don't require auth 
//  set saslLoginFailed to true to simulate the LoginException 
//  aborting multi shouldn't leave any record. 
//  The only requests that should be on toBeApplied are write   requests, for which we will have a hdr. We can't simply use   request.zxid here because that is set on read requests to equal   the zxid of the last write op. 
/*                              * If don't have challenge yet, skip sending                             * notification                              */
//  things needed for waitForNewLeaderAck to run (usually in leader.lead(), but we're not running leader here) 
//  also clears the wantClientAuth flag according to docs 
//  ..but consume (with a log message) all other types of exceptions. 
//  Member variables for mocking ZkDatabase 
//  else there is no need to clear the database    * When a new quorum is established we can still apply the diff      on top of the same zkDb data    * If we fetch a new snapshot from leader, the zkDb will be      cleared anyway before loading the snapshot 
// One time scheduling. 
//  Regardless of TICKET_RENEW_WINDOW setting above and the ticket expiry time,   thread will not sleep between refresh attempts any less than 1 minute (60*1000 milliseconds = 1 minute). 
//  by whether we have any pending buffers on the output queue or not 
//  we are throttled, so we need to queue 
//  remember these servers so we can add them back later 
/*  DNS resolution tests  */
//  Try to load a password-protected private key with the wrong password 
//  force a buffer fill on next read 
//  Test view contains other servers 
//  Make sure the first handshake completed and only the second   one failed. 
//  The value of callCount can exceed 1 only if the callback thread 
// we will get a checksum failure 
//  Read the log back from disk, this will throw a java.io.IOException: CRC check failed prior to ZOOKEEPER-2249 
//  Account for running within IKVM and create a new MBeanServer   if the PlatformMBeanServer does not exist. 
//  Registers shutdown handler which will be used to know the 
//  session moved is a connection level error, we need to tear   down the connection otw ZOOKEEPER-710 might happen   ie client on slow follower starts to renew session, fails   before this completes, then tries the fast follower (leader)   and is successful, however the initial renew is then   successfully fwd/processed by the leader and as a result   the client and leader disagree on where the client is most   recently attached (and therefore invalid SESSION MOVED generated) 
//  If have received from all nodes, then terminate 
//  we're done; don't expect to send another BIND 
/*      * (non-Javadoc)     *     * @see org.apache.zookeeper.Watcher#process(org.apache.zookeeper.WatcherEvent)      */
//  write length of message 
/*  Reconfig tests with IP addresses  */
/*      * Flag to determine whether to authenticate or not      */
//  Since the proposal has been committed we need to send the   commit message also 
//  now corrupt the snapshot 
//  reset cnxn factory 
/*      * To enable observers to have no identifier, we need a generic identifier     * at least for QuorumCnxManager. We use the following constant to as the     * value of such a generic identifier.      */
//  Try connecting with the same session id on a different 
//  A session can both be a local and global session during   upgrade 
//  directories 
//  Ignoring exception. If there is an interrupted exception   then one of the following assertion will fail 
//  and try to renew the ticket. 
//  finally, we should also check that the lag-off server has updated 
//  create 3 servers 
// CheckedOutputStream cout = new CheckedOutputStream() 
//  @see jira issue ZOOKEEPER-961 
//  We start at 1 because / will create an empty part first 
// If wins the challenge, then close the new connection. 
//  Thrown if the caller does not have permission to retrieve the Configuration.   In this case, simply returning false is correct. 
//  this is ok, it just means that the session revalidation failed. 
//  this is fine 
//  verify that now ZooKeeper service is up and running 
//  it should exist 
//  change everyone's leader election port 
//  the files we expected 
//  verify access using original auth 
//  specific election address 
//  node doesn't exists 
//  truncate it 
//  Snapshot containing 5000-byte znode and logfile containing create txn 
//  leader goes in looking state 
/*                      * This sleep time represents the time a follower                     * would take to declare the leader dead and start                     * a new leader election.                      */
//  Number of machines increased, my server is not in the new cluster 
/*          * peer1 and peer2 are A and B in the above example.          */
//  init connection executors 
/*      * Verify that all of the servers see the same number of nodes     * at the root      */
//  property is not set we should get the default value 
/*                      * Building challenge packet to send                      */
// tried all servers and couldn't connect 
//  This is the only place that can throw IO exception 
/*          * (non-Javadoc)         *          * @see javax.swing.tree.TreeNode#getAllowsChildren()          */
/*      * Generates 3 ports per server      */
//  is a CA 
//  Now do the tally 
/*  Pretend that any watcher exists  */
//  10.10.10.4:1238, 10.10.10.3:1237, 10.10.10.2:1236, 10.10.10.1:1235   10.10.10.3:1237, 10.10.10.2:1236, 10.10.10.1:1235 
//  This server should fail to join the quorum as it is not using TLSv1.2 
//  This method is to maintain compatiblity of startup(zks) and enable sharing of zks 
//  Assuming the packet will be sent out successfully. Because if it fails,   the channel will close and clean up queues. 
//  See ZooKeeper.java for an explanation of why we need @SuppressWarnings("try") 
//  create with CreateMode 
//     which means it acked from itself 
/*              * There are two things going on in the logic below:             *              * 1. skip comparing the zxid and electionEpoch for votes for servers              *    out of election.              *                 *    Need to skip those because they can be inconsistent due to               *    scenarios described in QuorumPeer.updateElectionVote.              *             *    And given that only one ensemble can be running at a single point              *    in time and that each epoch is used only once, using only id and              *    epoch to compare the votes is sufficient.             *             *    {@see https://issues.apache.org/jira/browse/ZOOKEEPER-1805}             *             * 2. skip comparing peerEpoch if if we're running with mixed ensemble              *    with (version > 0x0) and without the change (version = 0x0)              *    introduced in ZOOKEEPER-1732.             *             *    {@see https://issues.apache.org/jira/browse/ZOOKEEPER-1732}             *             *    The server running with and without ZOOKEEPER-1732 will return              *    different peerEpoch. During rolling upgrades, it's possible             *    that 2/5 servers are returning epoch 1, while the other 2/5             *    are returning epoch 2, the other server need to ignore the              *    peerEpoch to be able to join it.              */
//  we are done with deserializing the   the datatree   update the quotas - create path trie   and also update the stat nodes 
//  Restore the System property if it was set previously 
//  Do a simple operation to make sure the connection is fine. 
//  Current number of toaster... 
//  Check that the servers are up, have the right config and can process operations. 
//  need to cancel this selection key from the selector 
//  Data should get updated 
//  We throw LoginExceptions... 
//  materialize the watchers based on the event 
//  9. start follower A, after it's in broadcast state, make sure 
//  quorum as this needs auth. 
//  validate that the old value is there and not the new one 
//  read error and input streams as this would free up the buffers 
//  new RuntimeException("Calling shutdown").printStackTrace(); 
/*  Useful for testing watch handling behavior  */
//  SASL authentication completes. 
/*                      * We only partially sent this buffer, so we update                     * the position and exit the loop.                      */
//  Add multiple data watches 
//  create ephemeral znode 
//  This is a severe error that we cannot recover from,   so we need to exit 
//  but written out to the transaction log 
//  Rest of commands fail. 
//  no principals: must not be GSSAPI: use DIGEST-MD5 mechanism   instead. 
//  This is the same object as this.zk, but we cache the downcast op 
//  the version appended to filename should be the same as   the one of quorum verifier. 
//  Override setting in ZKTestCase 
// should not be able to remove follower 2 
//  1246, 1245, 1244, 1243, 1242, 1241,   1240, 1239, 1238, 1237 
//  lets either become the leader or watch the new/updated node 
//  servers list, but there's no "peerType=observer" token in config 
//  to be started (which should take one tickTime (2 seconds)) 
//  4. on the customized leader catch the startForwarding call      (without synchronized), set the node to value v1, then      call the super.startForwarding to generate the ongoing 
//  Let's just make sure it can still move 
//  ok, exception as expected. 
//  use out-of-band method to verify 
//  We track totals by seconds 
//  check that the dynamic configuration file contains the membership info 
//  get the args 
//  is available 
//  e.g. serviceHostnameAndKerbDomain := 
//  start taking old servers 
/*          * When leader election is completed, the leader will set its         * lastProcessedZxid to be (epoch < 32). There will be no txn associated         * with this zxid.         *         * The learner will set its lastProcessedZxid to the same value if         * it get DIFF or SNAP from the leader. If the same learner come         * back to sync with leader using this zxid, we will never find this         * zxid in our history. In this case, we will ignore TRUNC logic and         * always send DIFF if we have old enough history          */
//  Remove all the watchers for the given path 
//  we don't backup static config for standalone mode.   we also don't backup if reconfig feature is disabled. 
//  wait for the the request processor to do his job 
//  We should be able to reconnect with the same session id on a 
//  just make sure that we actually did get it in process at the 
/*          * Send follower info, including last zxid and sid          */
//  On Java 9 and later, prefer GCM ciphers due to improved AES-NI support. 
//  simulate the upgrading scenario, where the reconfig znode 
//  Another client deleted the node first. 
//  Clean up the dead machines 
//  Since we preallocate, we define EOF to be an 
//  This test takes too long tos run! 
//  changing a server's role / port is done by "adding" it with the same 
//  We send TRUNC to 3 and forward any packet starting at 
//  need to wake on connect success or failure to avoid   timing out ClientCnxn.SendThread which may be   blocked waiting for first connect in doTransport(). 
//  file should not exist 
//  start old cluster 
//  Since client's authentication with server is in progress,   send only the null-header packet queued by primeConnection().   This packet must be sent so that the SASL authentication process   can proceed, but all other packets should wait until 
//  We send TRUNC to 3 and forward any packet starting at maxCommittedLog 
//  set shutdown flag 
//  everything went ok 
//  first line should be version info 
//  Push an update request on the queue to resume selecting   on the current set of interest ops, which may have changed 
//  Inform /foo2 update 
/*      * Negative counter for observer server ids.      */
//  to keep the quorum peer running and force it to go into the looking state, we kill leader election 
//  1. set up an ensemble with 3 servers 
// Anything after this needs to go to the transaction log, not applied directly in memory 
//  servers 0 and 1 should connect to all servers, including the one in 
//  make sure we have all servers listed 
/*          * Current state;          */
//  Property value takes precedence if provided 
/*      * Counter to count connection processing threads.      */
//  Delaying the zk server startup so that   ZooKeeperServer#sessionTracker reference won't be   initialized. In the defect scenario, while processing the   connection request zkServer needs sessionTracker reference,   but this is not yet initialized and the server is still in   the startup phase, resulting in NPE. 
/*      * Default value of peer is participant      */
//  Now, try an ephemeral node. This will trigger session upgrade   so there will be createSession request inject into the pipeline 
//  2. SASL authentication has succeeded or failed.. 
//  is older than on-disk txnlog 
//  Header   Base64 text   Footer 
//  just move it to the new list 
/*  members - comma separated list of new membership information (e.g., contents of a membership     * configuration file) - for use only with a non-incremental reconfiguration. This may be specified     * manually via the -members flag or it will automatically be filled in by reading the contents     * of an actual configuration file using the -file flag.      */
//  if the server is not running or hits an internal error. 
/*      * Reception queue      */
//  Simple error checking for conflicting modes 
//  Prime the server that is going to come in late with 50 txns 
//  Validate that we don't see any txn from the second session 
//  could not create tmp directory to hold JAAS conf file : test will fail now. 
//  If running outside the context of Ant or Ant is using a single   test process, then use all valid ports. 
//  this is the backwardCompatibility mode in place before ZK-107   It is for a version of the protocol in which we didn't send peer epoch 
//  Data watcher 
//  1 follower out of 3 is not a majority 
//  Check that the first operation is successful in all request 
//  check throttling 
//  start servers 
/*          * Epoch          */
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#     * getChildren(java.lang.String)      */
//  current leader candidate 
//  disconnect the client by killing the socket, not sending the   session disconnect to the server as usual. This allows the test   to verify disconnect handling 
//  Delete the first log file, so we will fail to read it back from disk 
//  since user has provided sessionId 
//  the outgoing queue will be sent to the Zookeeper server. 
//  Nothing needed 
//  Peer miss the committedLog and txnlog is disabled 
//  Didn't read anything within the timeout, fallthrough and assume the connection is plaintext. 
//  to the start of the txn 
//  Number of znodes this test creates in each snapshot. 
/*          * Message tag          */
//  add itself 
//  this node does not have a child   is the leaf node   check if its the leaf node 
//  This will wake up the accept thread and the other selector   threads, and tell the worker thread pool to begin shutdown. 
//  fle = fast leader election 
//  add a new node, should trigger a watch 
//  scenario where only three parameter are passed 
//  servers without any authentication configured 
//  Verify no zoo.cfg.dynamic and zoo.cfg.bak files existing locally   when reconfig feature flag is off by default. 
//  visible for testing 
//  we are setting the num quota 
//  this should flush the config to servers 2, 3, 4 and 5 
// Create a DataTree with quota nodes so PathTrie get updated 
//  handshake. 
//  2 servers in current config, 3 in next config 
//  have we read length bytes?
//  this is normal. For example - server found out about new config through FastLeaderElection gossiping   and then got the same config in UPTODATE message so its already known 
//  Simulating FinalRequestProcessor logic: create session request has   delayed and now reaches FinalRequestProcessor. Here the leader zk 
//  Note: SimpleChannelInboundHandler releases the ByteBuf for us   so we don't need to do it. 
//  scenario where four parameter are passed 
// 4. Restart peer2 with quorum.auth.learnerEnableSasl=false and   quorum.auth.serverRequireSasl=false. It should fail to join the 
//  new members are initialized with current config + the new server 
//  Port changes after bind() if the original port was 0, update   localAddress to get the real port. 
//  Member variables for mocking Leader 
//  case-1) 'quorum.auth.enableSasl' is off. Tries to enable server sasl. 
//  second add to electingFollowers, verifier.containsQuorum=true, waitForEpochAck returns without exceptions 
//  should cause "/foo/bar" and "/foo" to get deleted when checkContainers() is called 
//  Remove "server.x=" prefix which quorum peer does not include. 
//  Extract keyword arguments to command from request parameters 
/*      * (non-Javadoc)     *     * @see org.apache.zookeeper.server.ServerCnxnIface#sendResponse(org.apache.zookeeper.proto.ReplyHeader,     *      org.apache.jute.Record, java.lang.String)      */
//  we don't have a designated leader - need to go into leader   election 
//  localPeerBean.1 of ReplicatedServer_1 
//  cannot create ephemeral nodes on a local session. 
//  Got expected exception 
//  for i < (numClients/2) this tests the case currentHost == null &&   reconfigMode = true   for i >= (numClients/2) this tests the case currentHost!=null &&   reconfigMode = true 
//  Test that sequential filenames are being created correctly, 
//  Don't schedule the purge task with zero or negative purge interval. 
//  We may get the correct exception but the txn may go through 
//  We send DIFF to (6,0) and forward any packet starting at (5,0) 
//  ensemble and will reject it. 
//  ValidateProcessor is set up in a similar fashion to ToBeApplied   processor, so it can do pre/post validating of requests 
//  Returned empty set must not be modifiable 
//  not writing them back to static file 
//  shut servers 0..2 down 
//  notifies watcher removal 
//  We'll fill this in later 
//  Exists watcher 
//  shutdown the previous zk 
//  Mark this connection as once again ready for selection 
//  the following statement will throw. 
/*      * Test that a reconfiguration fails if the proposed change would leave the     * cluster with less than 2 participants (StandaloneEnabled = true).     * StandaloneDisabledTest.java (startSingleServerTest) checks that if     * StandaloneEnabled = false its legal to remove all but one remaining     * server.      */
// Process has not terminated.  So check if it has completed   if not just destroy it. 
//  "myhost.foo.com@FOO.COM" 
//  On entry to this method, qcm must be non-null and the locks on both qcm and QV_LOCK   must be held.  We don't want quorumVerifier/lastSeenQuorumVerifier to change out from   under us, so we have to hold QV_LOCK; and since the call to qcm.connectOne() will take   the lock on qcm (and take QV_LOCK again inside that), the caller needs to have taken 
//  If we already started writing p, p.bb will already exist 
//  by default create this directory, but otherwise complain instead   See ZOOKEEPER-1161 for more details 
//  2 is down. 
//  Must be Java 1.8 or earlier 
//  Client only has 1 outgoing socket, so the event loop group only needs   a single thread. 
//  this is valid node for quota 
// 10 seconds 
/*      * Tests that an incremental reconfig fails if the current config is hiearchical.      */
// are cleared 
//  zxid should be non-null too 
//  shut them down and then simulate a reboot with a reconfig in progress 
//  new followers. 
/*      * Socket options for TCP keepalive      */
//  Possible since it's just deserialized from a packet on the wire. 
//  all clients should be connected 
//  When Leader.shutdown() calls ss.close(),   the call to accept throws an exception.   We catch and set stop to true. 
//  Visible for testing 
/*          * Reset incomingBuffer          */
//  tests the case currentHost == null && lastIndex == -1   calls next for clients with index < numClients/2 
//  make sure we have these 5 servers listed 
//  accepted epoch = 5 it should now have 6 
//  Trying to load a PEM file with PKCS12 loader should fail 
//  Sun doesn't include the address that causes this   exception to be thrown, also UAE cannot be wrapped cleanly   so we log the exception in order to capture this critical   detail. 
//  maximum retry count while trying to bind to election port 
//  Font used to display message 
//  server login 
//  Both servers 0 and 1 will have the .next config file, which means 
//  if the close operation (rename) fails we'll get notified.   worst case the tmp file may still exist 
//  the scenario that inspired this unit test 
//  Test that with no snaps, findNRecentSnapshots returns empty list 
// check if I'm in the new configuration with the same quorum address -  
// using linux bash commands to retrieve info 
//  Map the elem to the new expiry time. If a different previous 
//  We don't validate right away, will do another session create first 
//  lower-bound grace period to 2 secs 
/*              * The default QuorumVerifier is QuorumMaj              */
//  Java 8 default should have the CBC suites first 
//  find some server that's staying 
//  
//  number of servers stayed the same or decreased 
//  closing the resources 
// LOG.info("Closed client: " + zk.describeCNXN()); 
//  this is ok -- just a packet from an old server which   doesn't contain readOnly field 
//  Arrange & Act 
//  110 character base path 
//  Do 25% write / 75% read request mix 
//  to send the watches 
//  before restart 
//  delete any already existing .next file 
//  setData using chRoot client. 
//  Default white list for 3.5.x is empty, so all command should fail. 
//  This will add to local session tracker if it is enabled 
//  wait some time to let this get written to disk 
//  The leader should time out and remaining servers should go into   LOOKING state. A new leader won't be established since that   would require completing the reconfig, which is not possible while 
/*  Rollback change records from failed multi-op  */
//  Returns the serverId from the sessionId (the high order byte) 
//  SessionExpiredException as the previous local session was not persisted). 
//  2 servers in current config, 5 in next config 
//  We need to set isLocalSession to tree for these type of request   so that the request processor can process them correctly. 
//  Arrange   [testhost-3.testdomain.com:1237, testhost-2.testdomain.com:1236, testhost-1.testdomain.com:1235] 
//  Read the uptodate ack 
//  observer calls waitForNewLeaderAck, should fail verifier.containsQuorum 
//  ensure all servers started 
//  stop() called shortly after start(), before   this thread started running. 
//  Strip leading "/" 
//  machine is under load 
//  wait for the falseLeader to disconnect 
//  2. Verify whether the connecting host is present in authorized hosts.   If not exists, then connecting peer is not authorized to join the 
//  newly elected zookeeper quorum. 
//  compatibility. 
//  rethrow exception 
//  cool now make it V1. a -1 parentCVersion will   trigger fixup processing in processTxn 
//  Disable sending DIFF using txnlog, so that this test still   testing the ZOOKEEPER-962 bug 
//  4. authenticating object exists, so ask it for its progress. 
//  Use txnlog and committedLog to sync 
//  execute writer operation and flush 
//  EOF or corrupted record 
//  set peer's server to null 
//  Check that the second operation failed after the first request 
//  restore socket timeout to the old value 
//  ensure at least the two clients we created are accounted for 
//  don't delete tmpFile - this ensures we don't attempt to create   a tmpDir with a duplicate name 
//  disable it if enabled 
//  close the session and newly created ephemeral node should be deleted 
//  only 1 commit, otherwise it will be flaky   Then ... verify serverStats is updated to the number of commits (as threshold is set to 0) 
//  Clean up dead sessions 
/*      * Max buffer size to be read from the network.      */
//  Send a diff 
//  This server should fail to join the quorum as it is not using one of the supported suites from the other 
//  before connecting to quorum, servers should have set up dynamic file   version and pointer. And the lag-off server is using the older   version dynamic file. 
//  This should never happen when executing reconfig command line,   because it is guaranteed that we have a ZooKeeperAdmin instance ready   to use in CliCommand stack.   The only exception would be in test code where clients can directly set   ZooKeeper object to ZooKeeperMain. 
//  Using the old PlainSocketImpl (prior to JDK 13) we expect to get Socket Exception 
//  when a reconfig occurs where the leader is removed or becomes an observer,  
//         ZooKeeper zk = createClient();            long sessionId = zk.getSessionId();          byte[] passwd = zk.getSessionPasswd();          zk.close();            zk.close();            LOG.info("Closed first session");            startSignal = new CountDownLatch(1);          zk = new ZooKeeper(HOSTPORT, CONNECTION_TIMEOUT, this,                  sessionId, passwd);          startSignal.await();            LOG.info("Opened reuse");            Assert.assertEquals(sessionId, zk.getSessionId());            zk.close();      } 
//  we're good 
//  we do not want to wait for a session close. send it as soon as we   detect it! 
//  we can just ignore because the child watcher takes care of this 
/*          * current state of sender          */
//  get path [watch] 
//  SSL prohibits unilateral half-close 
//  try to access it with different user (myuser) 
//  test failed somehow. 
//  guarded by sync 
//  Close the session. 
//  for self-signed certs, issuer == subject 
//  connect to it 
//  of updates; see the implementation comment at setLastSeenQuorumVerifier(). 
//  close the bad client socket immediately 
/*      * Test if a receiveConnection is able to timeout on socket errors      */
//  Verify that server is following and has the same epoch as the leader 
//  For tests and NettyServerCnxnFactory only, thus package-private. 
/*                              * We want to make sure we implement the state machine                             * correctly. If we are a PARTICIPANT, once a leader                             * is elected we can move either to LEADING or                              * FOLLOWING. However if we are an OBSERVER, it is an                             * error to be elected as a Leader.                              */
//  Change the election round for one of the members of the ensemble 
//  log warning message if there is no matching commit   old leader send outstanding proposal to observer 
//  Validate data on both follower and leader 
//  start all the servers 
//  [testhost-3.testdomain.com:1237, testhost-2.testdomain.com:1236, testhost-1.testdomain.com:1235] 
//  If we explicitly close the session, then the session id should no 
/*                                  * Send a notification back if the peer that sent this                                 * message is also looking and its logical clock is                                 * lagging behind.                                  */
//  e.g. servicePrincipalName := "zookeeper" 
//  validate typical case - requested == negotiated 
//  server and the local session was not persisted). 
//  the connecting peer (id = 2) is a 3.4.6 observer 
//  GSSAPI: server sends a final packet after authentication succeeds 
//  Peer has zxid of epoch 3 
//  Force snapshot and restore 
//  Do Nothing 
//  hdm.addLoggerMBean(rootLogger.getName()); 
//  If version can't be parsed, use the more conservative Java 8 default 
//  ZOOKEEPER-2467 : Testing negative number for redo command 
//  @see jira issue ZOOKEEPER-706. Test auto reset of a large number of 
//  If we are in read-only mode, seek for read/write server 
//  Lost quorum of last committed and/or last proposed   config, set shutdown flag 
/*              * Have to wait for the first ACK, wait until             * the leader is ready, and only then we can             * start processing messages.              */
//  Shutdown Zookeeper. 
//  second chance...   in some cases, leader change in particular, the timing is   very tricky to get right in order to assure that the client has   disconnected and reconnected. In some cases the client will   disconnect, then attempt to reconnect before the server is   back, in which case we'll see another connloss on the operation   in the try, this catches that case and waits for the server   to come back 
//  force the zxid to be behind the content 
//  different zxids for a server depending on timing. 
//  Sends connection request asynchronously if the quorum   sasl authentication is enabled. This is required because   sasl server authentication process may take few seconds to   finish, this may delay next peer connection requests. 
//  suppose that this new server never heard about the reconfig proposal 
/*      * Test if Worker threads are getting killed after connection loss      */
//  With the defect, leader hangs here also, but with fix   it does not 
//  Capture the command name from the URL 
//  clear pending revalidations 
//  expected, sort of 
/*              * Later epoch              */
//  Start with 9 servers and 10000 clients 
//  Initialize 'lastLogin' to do a login at first time 
//  accept, maxClientCnxns, configureBlocking 
//  start server again with corrupted database 
//  Don't leak sockets on errors 
//  determine whether we need to send an AuthFailed event. 
//  disable Client Sasl 
//  create transaction and snapshot files in data directory 
//  the first poll is just a session delivery 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorManager#     * saveDefaultConnectionFile(java.util.Properties)      */
//  different server, since it has been propagated. 
//  correct 
//  Connection set is relied on heavily by four letter commands 
//  compare http://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html 
//  ... then disable throttling after 2 seconds. 
//  Using the NioSocketImpl after JDK 13, the expected behaviour on the client side   is to reach the end of the stream (bytesRead == -1), without a socket exception. 
//  Utility method that recreates a new ZooKeeperAdmin handle, and wait for the handle to connect to 
//  number of servers increased 
//  ensure it closes - in particular wait for thread to exit 
//  reset for next run 
//  Populate DIGEST-MD5 user -> password map with JAAS configuration entries from the "Server" section.   Usernames are distinguished from other options by prefixing the username with a "user_" prefix. 
//  First test to see if the watch survives across reconnects 
//  getters 
//  Imp: Safer side catching all type of exceptions and remove 'sid'   from inprogress connections. This is to avoid blocking further   connection requests from this 'sid' in case of errors. 
//  lets change leader to observer 
//  ensure server started 
//  Peer has zxid of epoch 1 
//  prevent untyped construction 
//  renewal thread's main loop. if it exits from here, thread will exit. 
//  the start of second log, since the first one is removed 
//  nextProcessor returns. 
/*      * See <a href="{@docRoot}/../../../docs/zookeeperAdmin.html#sc_zkCommands">     * Zk Admin</a>. this link is for all the commands.      */
//  Getting NEWLEADER here instead of in discovery    means this is Zab 1.0 
//  Guarantee that the final token is the one we're expanding 
//  already has quota 
//  Verify ACLs in the response 
//  ZooKeeper server supports two kinds of connection: unencrypted and encrypted. 
//  make sure that the error thread exits 
//  Unknown session 
//  quorum servers. 
//  Peer has zxid of epoch 0 
//  test old cluster 
/*      * Thread to run an instance of leader election for      * a given quorum peer.      */
// the directory containing the 
// Spy on ZK so we can check if a snapshot happened or not. 
//  verify no access 
//  This should fail since the buffer size > the data size due to extra fields 
//  if we can get here, it is a valid global session 
//  session is setup 
//  Set currentlyCommitting so we will block until this   completes. Cleared by CommitWorkRequest after 
//  expiry is before next scheduled refresh). 
//  New server type need to handle in-flight packets 
//  This will remove the cnxn from cnxns 
//  open a connection 
//  Use them all except one to build the ensemble 
//  modify follower's client port 
//  read "is read-only" flag 
//  Send closeSession request. 
//  the server should respond within 10s 
//  element, take, and remove follow the same pattern.   We want to return the child node with the smallest sequence number.   Since other clients are remove()ing and take()ing nodes concurrently,    the child with the smallest sequence number in orderedChildren might be gone by the time we check.   We don't call getChildren again until we have tried the rest of the nodes in sequence order. 
//  Make a clean snapshot 
//  clear out the ref to ensure no reuse 
//  servers 1 and 2 should be able to work independently 
//  setup session tracker 
//  This has to be set to null when the same instance of this class is reused between test cases 
//  "zookeeper/myhost.foo.com@FOO.COM" 
//  Do nothing, Observers keep themselves to   themselves. 
//  when local=true, here if connection not available, simply removes 
//  backward compatibility - dynamic configuration in the same file as 
//  access only inside synchronized(handshakeCompletedLock) { ... } blocks 
//  trigger the watches 
//  sleep for 10 seconds. 
//  including the lag-off server. 
//  Code unfortunately must be duplicated below since we can't assign   anything   before calling super 
//  Setup a database with two znodes 
//  Find the log file that starts before or at the same time as the   zxid of the snapshot 
//  mutators 
//  Handshake will take place, and then X509AuthenticationProvider should reject the untrusted cert 
//  Make the transaction log directory read only 
//  expecting close to log session closure 
//  1: create ephemeral node 
//  The QuorumCnxManager is held through an AtomicReference to ensure cross-thread visibility 
//  For Invalid dataversion number should not throw exception 
//  expected 
//  if idx is the the leader then everyone will get disconnected,   otherwise if idx is a follower then just that client will get 
//  This will wake up the selector threads, and tell the   worker thread pool to begin shutdown. 
//  again after leader election 
//  Trigger a GC. This will hopefully (but not necessarily) print   details about detected leaks to standard error before the error   is thrown. 
//  Need check if the record is a DataNode instance because of changes in ZOOKEEPER-2014   which adds default ACL to config node. 
//  Peer has zxid that we have never seen 
/*      * Start up the ZooKeeper server.     *     * @param args the configfile or the port datadir [ticktime]      */
//  Nodes 2 and 3 now form quorum and fully start. 1 attempts to vote for 3, fails, returns to LOOKING state 
//  unregister from JMX 
//  Change the quorum system from majority to hierarchical. 
//  check session close request 
//  returns whether we are interested in writing, which is determined 
//  Expect this to fail, the trust store does not contain a private key 
//  Use the odd one out for the client 
//  verify node delete watcher 
//  this case is not tested so throw the expected exception 
//  and so on 
//  not logs or anything else (per ZOOKEEPER-2420) 
//  0xff = Extended feature is ON   0x0000 = Extended type id TTL (0) 
//  longer be valid. 
//  And now it goes back to normal next() so it should be everything 
//  Mutation packets will be queued during the serialize,   so we need to mark when the peer can actually start   using the data 
//  Shutdown for the last time. 
//  queue 
// update the current candidate, and if it is the only one remaining, return it 
//  should never ever happen 
//  check get 
/*         * If we have a majority, then we are good to go.         */
//  Label to store Icon 
//  waiting for the session expiry 
//       throw new RuntimeException("My id " + myid + " not in the peer list");  } 
//  Additional sanity checks on content selected by wildcard can be done here 
/*  nada  */
// have the new credentials (pass it to the LoginContext constructor) 
//  protected by synchronized(this) 
//  4. wait one of the follower to be the new leader 
//  Exception is expected 
//  Just create some node so that we know the current zxid 
//  wait for the setData txn being populated 
//  wrap SASL response token to client inside a Response object. 
//  ensure no beans are leftover 
//  Reconfig node is access controlled by default (ZOOKEEPER-2014). 
//  initializing it for new connection 
// 2 should elect itself as leader and run by itself 
//  next) 
//  give dataTree a chance to sync its lastProcessedZxid 
//  The child might already be deleted during taking fuzzy snapshot,   but we still need to update the pzxid here before throw exception 
//  lets kill the leader and see if a new one is elected 
// When we lock markerNode, allow writeRecord to continue 
//  Below commands all need a live connection 
//  org.apache.log4j.Logger.getRootLogger(); 
// do nothing 
//  should not happen 
//  Check for a valid snapshot 
//  close() could have been called if receiveMessage() failed 
//  Move back to the old port 
//  Register a watch on the node 
//  do not add non quorum packets to the queue. 
//  false means that the session has expired 
//  check if all the followers are alive 
//  Adding pre-created watcher 
//  Since sessionTracker and syncThreads poll we just have to   set running to false and they will detect it during the poll 
// this.numRequestsProcessing.incrementAndGet(); 
// we do not need to make a copy of node.data because the contents  are never changed 
//  Set to true when connected to a read-only server, or a read-write (quorum) server. 
//  parse out chroot, if any 
//  Prepare a thread that will create znodes. 
//  thread object 't' will be null if a refresh thread is not needed. 
//  Just in case 
//  GSSAPI. 
//  The bug will manifest itself here because zkIdle will expire 
//  1. Authentication hasn't finished yet: we must wait for it to do so. 
//  Re-connect the client (in case we were connected to the shut down 
//  ignore connectionloss when removing from local   session 
//  assuming the first packet is the priming packet. 
//  since this is single buffer being resused   we need   to truncate the previous bytes of string. 
/*      * Does create/delete depending on the type and verifies     * if cversion before the operation is 1 less than cversion afer.      */
//  Just make sure we are good when admin made some mistakes in config file. 
//  file when they boot 
/*  Delete  */
//  Receive challenge request 
//  Ensure that we can convert all valid integers to KeeperStates 
//  shutdown the server 
// if this server is voter in new config with the same quorum address,   then it will remain the leader  otherwise an up-to-date follower will be designated as leader. This saves 
//  cluster 
//  if the client is not currently connected to any server 
/*          * (non-Javadoc)         *          * @see javax.swing.tree.TreeNode#getChildCount()          */
//  TODO partitioning of peers and clients 
//  Run servers 0..2 for a while 
//  HBase currently adds a single server line to the config, for   b/w compatibility reasons we need to keep this here. If standaloneEnabled   is true, the QuorumPeerMain script will create a standalone server instead   of a quorum configuration 
//  now check if its one of the zookeeper node child 
//  even though followers timed out, their ids are in connectingFollowers, and their   epoch were accounted for, so the leader should not block and since it started with  
//  channel disconnection happened 
/*  This file copied from Hadoop's security branch,  * with the following changes:  * 1. package changed from org.apache.hadoop.util to  *    org.apache.zookeeper.  * 2. Usage of Hadoop's Configuration class removed since  *    it is not available in Zookeeper: instead, system properties  *    are used.  * 3. The deprecated getUlimitMemoryCommand() method removed since  *    it is not needed.   */
//  multi record:     set "/foo" => succeed, leave a outstanding change     delete "/foo" => fail, roll back change 
//  independently of the client socket implementation details, we always make sure the   server didn't receive any data during the test 
//  single address not extracted 
/*          * (non-Javadoc)         *          * @see javax.swing.tree.TreeNode#getIndex(javax.swing.tree.TreeNode)          */
/*      * Counter to count worker threads      */
//  serialize the data with one znode with acl 
// addr should never be null, but just to make sure 
//  1. SASL client is disabled. 
//  cut the tree till their is more than one child 
//  Start Admin server 
/*                  * Decrement outstanding request count. The processor may be                 * blocked at the moment because it is waiting for the pipeline                 * to drain. In that case, wake it up if there are pending                 * requests.                  */
//  config + itself 
// the timeout thread handling 
//  zxid should still be previous result because record's not changed. 
//  6 is not in the view - its vote shouldn't count 
/*      * The control sequence sent by the telnet program when it closes a     * connection. Include simply to keep the logs cleaner (the server would     * close the connection anyway because it would parse this as a negative     * length).      */
//  DIFF + 1 proposals + 1 commit 
//  org.apache.log4j.jmx.HierarchyDynamicMBean hdm = new org.apache.log4j.jmx.HierarchyDynamicMBean(); 
/*  to be safe we just create a new         * datatree.          */
// add partcipants  change to observers 
// LOG.trace(e); 
//  This test simulate the usual rolling restart with no membership change:   1. A node is shutdown first (e.g. to upgrade software, or hardware, or cleanup local data.).   2. After upgrade, start the node.   3. Do this for every node, one at a time. 
//  any reconfig is invoked 
// Thread.sleep(60000);  assertTrue(message, fdCount <= initialFdCount); 
//  limited number of retries. 
//  Else what we are expecting since there are no outstanding watches 
//  Note: we don't care about delete events 
//  set auth using digest 
//  lets force the recreation of the id 
//  find most idle node 
//  four letter words take care   need not do anything else 
//  prior to this request 
//  watches set below exceeds 1MB. 
//    test get/exists with single set of watchers     get all, then exists all 
//  After leaving listener thread, the host cannot join the   quorum anymore, this is a severe error that we cannot   recover from, so we need to exit 
//  Both servers 0 and 1 will have the .next config file, which means   for them that a reconfiguration was in progress when they failed 
//  send error message to the learner 
//  Tells whether SSL is enabled on this ServerCnxnFactory 
//  iteration 
//  Peer has 0 zxid (new machine turn up), txnlog 
//  Make sure we can't convert from an invalid wrapper 
//  static configuration params see writeDynamicConfig() 
/*      * Object to synchronize access to recvQueue      */
//  list of followers that are ready to follow (i.e synced with the leader) 
//  and the leader will complete it. 
//  Set a small preAllocSize (.5 MB) 
//  Since JettyAdminServer reads a system property to determine its port,   make sure it initializes itself before setting the system property   again with the second port number 
//  the leader 
//  Verify correctness of data and whether sequential znode creation 
//  Node 1 is started without the leader (3) in its config view 
// noinspection PointlessBitwiseExpression   TTL_RESERVED_BIT is actually zero - but it serves to document that the proper extended bit needs to be set 
/*      * A peer can either be participating, which implies that it is willing to     * both vote in instances of consensus and to elect or become a Leader, or     * it may be observing in which case it isn't.     *     * We need this distinction to decide which ServerState to move to when     * conditions change (e.g. which state to become after LOOKING).      */
//  better: actions/help-about, but not in tango 
//  The password here is 'test'. 
//  Always treat packet from the client as a possible   local request. 
//  And the ephemeral nodes will be gone since the session died. 
//  commit (writes the new config to ZK tree (/zookeeper/config)                      
//  Form a quorum without ssl 
//  if there are multiple hostports, just take the first one 
//  Close connections still pending on the selector. Any others   with in-flight work, let drain out of the work queue. 
//  Again failure is expected because no ACL is associated with this user. 
/*  * This code is originally from HDFS, see the similarly named files there * in case of bug fixing, history, etc...  */
// set the session owner   as the follower that   owns the session 
//  simply return as there is a connection request to   server 'sid' already in progress. 
//  start server again 
//  Leave the bad client socket idle 
//  Add as global before removing as local 
//  respective reconnection interval 
//  append "am-I-allowed-to-be-readonly" flag 
//  read operation during r/o mode 
//  add it to pendingSyncs. 
//  Peer has zxid of epoch 2, so it is already sync 
//  add transaction log files to the snap version dir 
/*      * Creates a configuration string for servers 0..numServers-1 Ids in     * observerIds correspond to observers, other ids are for participants.      */
//  Find leader id. 
//  We now ship the request to the leader. As with all   other quorum operations, sync also follows this code   path, but different from others, we need to keep track   of the sync operations this Observer has pending, so we 
//  Act 
//  Empty snapshot and logfile containing a 5000-byte create 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorManager#removeWatchers     * (java.util.Collection)      */
//  5. send a create request to old leader and make sure it's synced to disk, 
//  quorum.auth.learnerRequireSasl=true, quorum.auth.serverRequireSasl=false 
//  make sure this is always synchronized with Zoodefs!! 
//  we know this from the data files   this node is the last node in the snapshot 
//  ZOOKEEPER-569:   If no votes are received for live peers, reset to voting   for ourselves as otherwise we may hang on to a vote 
//  close listen socket and signal selector threads to stop 
//  checking the child version using chRoot client. 
//  Setting this to "true" will enable encrypted client-server communication. 
//  Local session from other server 
//  assertFalse(log.hasWarned); 
/*          * Start server 0          */
//  Ignoring exception. If there is an ioexception   then one of the following assertion will fail 
/*          * (non-Javadoc)         *          * @see javax.swing.tree.TreeNode#getChildAt(int)          */
/*      * (non-Javadoc)     *     * @see org.apache.zookeeper.server.ServerCnxnIface#getSessionId()      */
/*      * (non-Javadoc)     *     * @see org.apache.zookeeper.Watcher#process(org.apache.zookeeper.proto.WatcherEvent)      */
//  create DataNode and call getChildren 
// that we can reconfigure down to one participant with observers. 
// make that testData exists otherwise it fails on windows 
//  Receive new message 
// 1000(1 second) is to prevent race condition missing to send the second ping  also make sure not to send too many pings when readTimeout is small  
//  normally because the leader didn't execute waitForEpochAck 
/*              * A snapshot might be in progress while we are modifying the data             * tree. If we set lastProcessedZxid prior to making corresponding             * change to the tree, then the zxid associated with the snapshot             * file will be ahead of its contents. Thus, while restoring from             * the snapshot, the restore method will not apply the transaction             * for zxid associated with the snapshot file, since the restore             * method assumes that transaction to be present in the snapshot.             *             * To avoid this, we first apply the transaction and then modify             * lastProcessedZxid.  During restore, we correctly handle the             * case where the snapshot contains data ahead of the zxid associated             * with the file.              */
//  succeed. We explicitly disable it at the top of X509Util.java. 
//  make sure the updates indeed committed. If it is not 
//  Simulating close session request: removeSession() will be executed 
//  note that the login object is static: it's shared amongst all zookeeper-related connections.   in order to ensure the login is initialized only once, it must be synchronized the code snippet. 
//  Some tests may not have a static config file. 
//    test get/exists with single set of watchers    get/exists together 
/*      * Local IP address      */
//  Stops automatic reads of incoming data on this channel. We don't   expect any more traffic from the client when processing a 4LW 
//  If previous state was not NEW, start() has already been called. 
// $NON-NLS-1$ 
//  Start up two of the quorum and add 10 txns 
//  Do some other update, so we bump the maxCommttedZxid 
//  remove hosts 7 and 8 (the last two in a list of 9 hosts) 
//  for sending over wire 
/*                      * Done with the election round, so now we set the vote in                     * the peer. A real zookeeper would take care of setting the                     * current vote. Here we do it manually.                      */
// commit and send some info 
//  close all open connections 
//  Follower is already sync with us, send empty diff 
//  roll the log 
//  this is negative, so that if a learner that does auth, connects to a   server, it'll think the received packet is an authentication packet 
//  The last valid ASCII character 
//  srvr is enabled by default due to the sad fact zkServer.sh uses it. 
/*      * Maximum capacity of thread queues      */
//  Creating chRoot client. 
//  Make sure we can instantiate a key manager from the PKCS12 file on disk 
//  This could happen both in static file or dynamic file. 
//  standalone server doesn't need myid file. 
//                 LOG.info("Testing " + i + " connections");              }              // We want to make sure socket descriptors are going away              zk = new ZooKeeper(hostPort, 30000, this);              zk.getData("/", false, new Stat());              zk.close();          }      } 
//  doesn't exist and the acl cache is empty 
/*                      * Get the current value of the logical clock for this peer                     * so that we know in which round this peer has executed.                      */
//  4 and 5 are observers, their vote shouldn't count 
//  refresh interval in msec   last time the command was performed   env for the command execution 
//  Add some timing margin for the quorum to elect a leader   (without this margin, timeouts have been observed in parallel test runs) 
//  authorized host lists 
//  Node 3 started second to avoid 1 and 2 forming a quorum before 3 starts up 
/*                  * Remove next notification from queue, times out after 2 times                 * the termination time                  */
//  children have changed, so read in the new list 
//  should be numClients/10 in expectation, we test that its numClients/10 +- slackPercent
//  Arrange   [testhost-4.testdomain.com:1238, testhost-3.testdomain.com:1237, testhost-2.testdomain.com:1236, testhost-1.testdomain.com:1235] 
//  The current protocol and two previous generations all send at least 28 bytes 
//  great this is what we want! 
/*              * The commit workers will have to execute this line before they             * wake up the commit processor. So this value is up-to-date when             * variant check is performed              */
//  send 0 if session is no   longer valid 
//  Restart ZK and observe a failure 
//  RemotePeerBean 
//  we are connected to a 1.0 server so accept the new epoch and read the next packet 
//  3 servers still up so this should work 
/*              * ZOOKEEPER-1863: continue only if there is no new request             * waiting in queuedRequests or it is waiting for a             * commit.               */
//  if we don't suspend a peer it will rejoin a quorum 
//  now lets stop the server 
//  zkServer.sh depends on "srvr". 
/*              * If using FLE, then every server requires a separate election             * port.              */
//  Since we don't check on the futures created by write calls to the channel complete we need to make sure   that all writes have been completed before closing the channel or we risk data loss   See: http://lists.jboss.org/pipermail/netty-users/2009-August/001122.html 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.encryption.DataEncryptionManager#decryptData     * (byte[])      */
//  We don't want to sleep on the first ever connect attempt. 
//  3 followers out of 5 are a majority of the voting view 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#     * getNodeIndex(java.lang.String)      */
/*          * Things we can only update after the whole txn is applied to data         * tree.         *         * If we update the lastProcessedZxid with the first sub txn in multi         * and there is a snapshot in progress, it's possible that the zxid         * associated with the snapshot only include partial of the multi op.         *         * When loading snapshot, it will only load the txns after the zxid         * associated with snapshot file, which could cause data inconsistency         * due to missing sub txns.         *         * To avoid this, we only update the lastProcessedZxid when the whole         * multi-op txn is applied to DataTree.          */
//  Directories are not used but we need it to avoid NPE 
//  queue the pair (watch set & event) for later processing 
/*      * getXid() is called externally by ClientCnxnNIO::doIO() when packets are sent from the outgoingQueue to     * the server. Thus, getXid() must be public.      */
//  Dump data to peer 
/*  Send a connect request. Any socket that has been closed (or at least                 * not added to the cnxn list on the server) will not have any bytes to                 * read and get an eof.                 *                 *  The trick here was finding a call that caused the server to put                 *  bytes in the input stream without closing the cnxn. None of                 *  the four letter commands do that, so we actually try to create                 *  a session which should send us something back, while maintaining                 *  the connection.                  */
//  run through till the counts no longer change on each server   max 15 tries, with 2 second sleeps, so approx 30 seconds 
//  also check to update the quotas for this node 
//  Test a hostname that resolves to a single address 
//  assertTrue(log.hasWarned); 
//  next scheduled refresh is sooner than (now + MIN_TIME_BEFORE_LOGIN). 
//  We send TRUNC and forward any packet starting lastProcessedZxid 
//  db is clear as part of deserializeSnapshot() 
/*              * Write a number of times until it             * detects that the socket is broken.              */
/*      * This class parses the initial identification sent out by peers with their     * sid & hostname.      */
//  Trying to get a first txn on the third give us the 
//  will do sessionTracker.addSession(id, timeout) 
/*  this means that we couldn't find any snapshot, so we need to             * initialize an empty database (reported in ZOOKEEPER-2325)  */
// check to see if zkDb is not null 
//  Upon reception of an ack message, remove it from the 
//  When ... 
//  when we add secureCnxnFactory. 
//  ... then force a throttled read after 1 second (this puts the read into queuedBuffer) ... 
/*              * Otherwise send to the corresponding thread to send.              */
//  Stop queuing connection attempts 
//  if we went to the next log file, we should call next() again 
//  The user did not override the default context. It might be that they just don't intend to use SASL,   so log at INFO, not WARN, since they don't expect any SASL-related information. 
//  this should only be for the beginning of the path   i.e. "/..." - split(path)[0] is empty string before first '/' 
//  so it should not do any work other than trace logging. 
//  Since pNew = 1 we should first try the new servers 
//  ZOOKEEPER-558:   In some cases the server does not close the connection (e.g., closeconn buffer   was not being queued  ZOOKEEPER-558) properly. This happens, for example,   when the client closes the connection. The server should still close the session, though. 
//  ignore exception 
//  TODO: introspect about runtime environment (such as jaas.conf) 
//  Resolve hostname for the remote server before attempting to   connect in case the underlying ip address has changed. 
// Another client removed the node first, try next 
//  Enumeration enumer = r.getCurrentLoggers(); 
//  Note: need to create a new ClientX509Util each time to pick up modified property value 
//  should cause "/foo" to get deleted when checkContainers() is called 
//  let it through, we don't require auth 
//  note that we should run the server, shut it down and only then   simulate a reconfig in progress by writing the temp file, but here no   other server is competing with them in FLE, so we can skip this step   (server 2 is booted after FLE ends) 
//  Last opened toaster 
//  take the first server on the list 
//  start server 2 with old config, where it is an observer 
//  Wait for the old leader to start completely 
//  lost the race, another thread already set the value 
//  DIFF + 3 proposals + 3 commit 
//  Initialized to 1 to prevent sending   stale notifications to peers 
// Add two participants and change them to observers to check 
//  this request came from someone else so just   send the commit packet 
//  track the number of records written to the log 
//  int percent = Integer.parseInt(timePercentCount[1]); 
//  OK to wait until socket disconnects while reading. 
//  Start thread that blast packets in the queue to learner 
//  '/multi' should have been deleted 
//  Assert   no exception thrown 
/* 	  Count number of log entries. Any line starting with a timestamp counts as an entry	 */
//  remotePeerBean.1 shouldn't exists in ReplicatedServer_3 
// votes[i] = v; 
//  revert back the error 
//  generate some transactions that will get logged 
//  and ensure trueLeader is still the leader 
//  sockKey may be concurrently accessed by multiple   threads. We use tmp here to avoid a race condition 
//  JAAS non-GSSAPI authentication: assuming and supporting only   DIGEST-MD5 mechanism for now.   TODO: use 'authMech=' value in zoo.cfg.
/*  *  Used to perform an atomic write into a file. *  If there is a failure in the middle of the writing operation,  *  the original file (if it exists) is left intact. *  Based on the org.apache.zookeeper.server.quorum.QuorumPeer.writeLongToFile(...) idiom *  using the HDFS AtomicFileOutputStream class.  */
/*          * If everyone else thinks I'm the leader, I must be the leader.         * The other two checks are just for the case in which I'm not the         * leader. If I'm not the leader and I haven't received a message         * from leader stating that it is leading, then predicate is false.          */
//  Create a new follower 
//  setup the messages to be streamed to follower 
//  Then ... 
//  nothing to prepend 
//  Verify serverStats is 0 before any commit 
//  If we cannot guarantee that this is strictly the starting txn   after a given zxid, we should fail. 
//  their are more child nodes   so just reset property. 
//  filter read requests 
//  we need to shutdown and start back up to make sure that the create session isn't the first transaction since 
//  find a follower 
//  XXX: Is lastProcessedZxid really the best thing to use? 
//  revert redirect of out/err streams - important step! 
//  transport 
//  old list (just the ports): 1238, 1237, 1236, 1235 
//  Remove all outstanding changes for paths of this multi.   Previous records will be added back later. 
//  When we explicitly close the session, we should not be able to 
//  Commit proposal may lag behind data tree, but it shouldn't affect   us in any case 
//  Check for race condition with session upgrading 
//  remotePeerBean.1 shouldn't exists in ReplicatedServer_2 
//  Peer has zxid of epoch 5 
//  [testhost-2.testdomain.com:1236, testhost-1.testdomain.com:1235] 
//  ignore timeout 
//  that add to outstandingChanges. 
//  clear all the connections on which we are selecting 
//  into looking state or following/leading state. 
//  Set to true if and only if constructor of ZooKeeperSaslClient 
//  This means reconfigMode = true, and nextHostInReconfigMode will be   called from next 
//  'rmr' is deprecated, so the test here is just for backwards 
//  setdata 
//  standalone mode - reconfiguration currently not supported 
//  in Zab V1.0 (ZK 3.4+) we might take a snapshot when we get the NEWLEADER message, but in pre V1.0   we take the snapshot on the UPDATE message, since Zab V1.0 also gets the UPDATE (after the NEWLEADER) 
//  Set the logical clock to 1 on fle instance of server 3. 
//  e.g. "zoo.cfg.dynamic", it returns null. 
//  check that the change has propagated to everyone 
//  Initialize Zookeeper again from the same dataDir. 
//  Peer has zxid of epoch 6 
//  Ensure we get the same value back after round trip conversion 
/*                              * Received ack successfully, so return                              */
//  Peer has zxid of epoch 4 
//  this is what we want 
/*          * Snapshots are taken lazily. It can happen that the child         * znodes of a parent are created after the parent         * is serialized. Therefore, while replaying logs during restore, a         * create might fail because the node was already         * created.         *         * After seeing this failure, we should increment         * the cversion of the parent znode since the parent was serialized         * before its children.         *         * Note, such failures on DT should be seen only during         * restore.          */
//  message with bad protocol version 
// setup servers 1-3 to be followers and 4 and 5 to be observers 
//  Border color 
/*  * This code is originally from HDFS, see the file name TestMiniKdc there * in case of bug fixing, history, etc. * * Branch : trunk * Github Revision: 916140604ffef59466ba30832478311d3e6249bd  */
//  We know the total JUnit process count and this test process's ID.   Use these values to calculate the valid range for port assignments   within this test process.  We lose a few possible ports to the   remainder, but that's acceptable. 
//  correctly 
//  Since all requests are passed to the request   processor it should wait for setting up the request   processor chain. The state will be updated to RUNNING   after the setup. 
//  some unexpected error, warn about it 
//  We expect two notifications before we want to continue         
//  create 7 servers 
// go over outstanding ops in order, and try to find a candidate that acked the most ops.  this way it will be the most up-to-date and we'll minimize the number of ops that get dropped 
// 2. Upgrade peer0,1,2 with quorum.auth.enableSasl=true and 
//  An authentication error occurred when the SASL client tried to initialize:   for Kerberos this means that the client failed to authenticate with the KDC.   This is different from an authentication error that occurs during communication   with the Zookeeper server, which is handled below. 
//  unnecessary code coupling. 
//  There are legal states in some use cases for null KeyManager or TrustManager.   But if a user wanna specify one, location is required. Password defaults to empty string if it is not   specified by the user. 
//  Change the snapcount to happen more often 
// invalid acl's 
//  this code requires a key in PKCS8 format which is not the default openssl format   to convert to the PKCS8 format you use : openssl pkcs8 -topk8 ... 
//  ignore as this is expected 
//  encoding 
//  There is no log record for the initial config, thus after syncing   with leader   /zookeeper/config is empty! it is also possible that last committed   config is propagated during leader election   without the propagation the corresponding log records.   so we should explicitly do this (this is not necessary when we're   already a Follower/Observer, only 
//  Local session from the leader 
//  Note that we make no effort here to remove empty mappings   from ipMap. 
//  recalculate the init limit time because retries sleep for 1000 milliseconds 
//  Start everyone but the leader 
//  Use DigestAuthenticationProvider.base64Encode or   run ZooKeeper jar with org.apache.zookeeper.server.auth.DigestAuthenticationProvider to generate password.   An example:   java -cp zookeeper-3.6.0-SNAPSHOT.jar:lib/log4j-1.2.17.jar:lib/slf4j-log4j12-1.7.5.jar:   lib/slf4j-api-1.7.5.jar org.apache.zookeeper.server.auth.DigestAuthenticationProvider super:test 
//  With peer epoch and version the message became 40 bytes 
/*                              * This predicate is true once we don't read any new                             * relevant message from the reception queue                              */
//  This isn't really an error txn; it just has the same   format. The error represents the timeout 
//  now check if their is already existing   parent or child that has quota 
//  save the found address so that it's used during the next   connection attempt 
//  fake propose request 
//  If we have a worker thread pool, use that; otherwise, do the work   directly. 
// the last snapshot seems incompelte   corrupt the last but one   and use that
//  wait for authFailed event from client's EventThread. 
//  This should stomp the zk handle 
//  Make sure we can instantiate a trust manager from the JKS file on disk 
//  add snapshot files to the log version dir 
//  provide time for the falseleader to realize no followers have connected 
//  Wait for request completion with timeout 
/*                          * If it is from a non-voting server (such as an observer or                         * a non-voting follower), respond right away.                          */
//  Do NOT trigger the reverse name service lookup. 
//  method always on top start only SINCE JDK 5 ! 
//  Calculate sizeLimit that we allow to retrieve txnlog from disk 
//  In the test below 1-9/10 = 1/10 chance of disconnecting 
/*          * Check if all groups have majority          */
//  Joiner initial config consists of itself and the leader. 
/*          * Address of the sender          */
//  remove the old files 
//  Empty snapshot and logfile containing a 1-byte create and 5000-byte set 
//  get information of current leader 
//  3. create a node 
//  Synchronized to sync the containers and ttls change, probably   only need to sync on containers and ttls, will update it in a 
//  If learner hasn't sync properly yet, don't send ping packet   otherwise, the learner will crash 
/*                      * Only proceed if the vote comes from a replica in the current or next                     * voting view for a replica in the current or next voting view.                      */
//  do create operation, so that injected IOException is thrown 
//  Before sending the request, check if the request requires a   global session and what we have is a local session. If so do   an upgrade. 
//  do nothing - exclude persistence from perf 
// LOG.warn("Set clientAddr to " + clientAddr); 
//  we got here, so the version was set 
//  Verify that the correct exception is thrown 
/*                  * put() is going to modify the positions of both                 * buffers, put we don't want to change the position of                 * the source buffers (we'll do that after the send, if                 * needed), so we save and reset the position after the                 * copy                  */
//  in order to be committed, a proposal must be accepted by a quorum.   
//  Set a combination of child/exists/data watches 
//  expected that 
//  stop old watcher if there is one 
//  test done - close the zk, not needed 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorManager#connect(java     * .util.Properties)      */
/*  Reusing the index variable to select a follower to connect to  */
//  check that a dynamic configuration file doesn't exist 
//  Note that we do not generate the Xid for the packet yet. It is   generated later at send-time, by an implementation of ClientCnxnSocket::doIO(), 
//  Color for border 
//  Since the file padding inserts a 0, we will fill the data with 0xff to ensure we corrupt the data if we put the 0 in the data 
//  Convert time -> sessions map to time -> session IDs map 
// start one server 
// the path does not exist  
//  This just avoids complaints by junit 
//  the following commands would not work in the original   cluster of 5, but now that we've removed 2 servers   we have a cluster of 3 servers and one of them is allowed to fail 
/*              * ZOOKEEPER-1624 - We need to store for parent's ChangeRecord             * of the parent node of a request. So that if this is a             * sequential node creation request, rollbackPendingChanges()             * can restore previous parent's ChangeRecord correctly.             *             * Otherwise, sequential node name generation will be incorrect             * for a subsequent request.              */
//  Give the worker threads time to finish executing 
//  request.addRQRec(">sync"); 
//  Should not have touched original file 
//  State of peer that sent this message 
/*          * This is going to reset the buffer position to 0 and the         * limit to the size of the buffer, so that we can fill it         * with data from the non-direct buffers that we need to         * send.          */
//  Avoid negative cxid values.  In particular, cxid values of -4, -2, and -1 are special and   must not be used for requests -- see SendThread.readResponse.   Skip from MAX to 1. 
//  establish the connection to the ZooKeeper cluster 
//  my server is in new config, but load should be decreased.   Need to decide if this client   is moving to one of the new servers 
//  Newer than committedLog, send trunc and done 
// force /bin/ls, except on windows. 
//  Process the touches 
//  see if its set 
/*  joining - comma separated list of server config strings for servers to be added to the ensemble.     * Each entry is identical in syntax as it would appear in a configuration file. Only used for      * incremental reconfigurations.      */
//  Look through the logs for output that indicates Node 1 is LEADING or FOLLOWING 
/*          * Leader epoch          */
//  We are going to look for a leader by casting a vote for ourself 
/*          * (non-Javadoc)         *          * @see javax.swing.tree.TreeNode#isLeaf()          */
//  don't allow redoing this redo 
//  Insert random delay to test thread race conditions 
//  Restart halted node and verify count 
// the snapshot directory 
//  create an extra handle, so we can index the handles from 1 to qu.ALL   using the server id. 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#     * hasChildren(java.lang.String)      */
//  Make sure we can instantiate a key manager from the PEM file on disk 
//  This code does not exists 
//  shutdown the server itself 
//  used for assertions later 
//  On my box, if selector.close() is not called fd diff is > 700. 
//  new config will have three of the servers as followers 
//  Instantiate Notification and set its attributes 
//  check if we have a version that includes config. If so extract config info from message. 
// Store off current pending change records in case we need to rollback 
//  close the existing txnLog and snapLog 
//  updates the dynamic file pointer 
//  tests the case currentHost == null && lastIndex >= 0 
//  if we can't skip, we should just read from the start 
//  make sure servers 0, 1 don't come online - this should be the case 
//  Similar to follower, we need to log requests between the snapshot   and UPTODATE 
//  wait for things to stabilize 
//  all clients should be disconnected 
//  note, setUp() enables this test based on the test name 
/*  we test a normal run. everything should work out well.  */
//  We send DIFF and forward any packet starting at maxCommittedLog 
//  Java 9+ default should have the GCM suites first 
//  execute output stream operation 
//  Everything below and until we get back to the select is   non blocking, so time is effectively a constant. That is   Why we just have to do this once, here 
//  Generate Xid now because it will be sent immediately,   by call to sendThread.sendPacket() below. 
//  joiner should have the following format: server.x = server_spec;client_spec                
// last proposed quorum verifier 
//  default hostprovider 
//  property is set but can not be parsed to int, we should get the 
/*          * Run another instance of leader election.          */
//  remember to close old instance before replacing it 
//  do nothing 
//  This server should join successfully 
//  create session with max value 
/*  Make sure to create a new object when changing  */
//  We only run if the readyNode exists 
//  Notify server state changes to the registered shutdown handler, if any. 
//  this should trigger the watch 
//  whether to remove the watches locally 
/*          * Start mock server.          */
//  run servers 0 and 1 normally 
//  checks that conditioning on version works properly 
//  ephemeral node is getting deleted. 
//  currentIndex was set by the call to updateServerList, which   called next 
//  Refresh the Ticket Granting Ticket (TGT) periodically. How often to refresh is determined by the   TGT's existing expiry date and the configured MIN_TIME_BEFORE_RELOGIN. For testing and development,   you can decrease the interval of expiration of tickets (for example, to 3 minutes) by running : 
/*          * Creating peer.          */
//  Leader mock: Prep -> MockProposal -> Commit -> validate -> Final   Have side thread call commitProc.commit() 
/*        * If the stat fails, the node has gone missing between the call to       * getChildren() and exists(). We need to try and become the leader.        */
//  The previous client connection to falseLeader likely closed, create a new one 
//  inject problem in server 
//  Try to provide hints to use about what went wrong so they   can fix their configuration.   TODO: introspect about e: look for GSS information. 
//  while OpCode.closeSession 
//  could not create tmp directory to hold JAAS conf file.
// 'groups username' command return is non-consistent across different unixes 
//  12725 days, about 34 years 
//  When incremented... 
//  Since we just shut down server 2, its still considered "synced"   by the leader, which allows us to start the reconfig   (PrepRequestProcessor checks that a quorum of the new   config is synced before starting a reconfig).   We try to remove server 3, which requires a quorum of {1,2,3}   (we have that) and of {1,2}, but 2 is down so we won't get a   quorum of new config ACKs. 
//  We don't want to receive any packets until we are sure that the 
//  Verify if there is any change in the proposed leader 
//  When reset... 
//  Simulate a socket channel between a client and a follower 
// last committed quorum verifier 
//  check duplication of addresses and ports 
//  bad hostport string 
//  sleep for 10 seconds 
//  this should exceed threshold (ZKDatabase.snapshotSizeFactor) 
//  adding back the packet to notify of failure in conLossPacket(). 
/*  Reconfig test with unresolved hostnames  */
//  ignore, close the send/event threads 
//  make streams and socket do something innocuous 
//  There is ACL however the permission is wrong - need WRITE permission at leaste. 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#     * getNodeMeta(java.lang.String)      */
//  don't care about the version if it's in LOOKING state 
//  create the pkg directory 
//  We can only test calls to ZKTrustManager using Sockets (not SSLEngines). This can be fine since the logic is the same. 
//  setConfiguration() will work even if the above try() fails due   to a missing Kerberos configuration (unless zookeeper.requireKerberosConfig   is set to true, which would not allow execution to reach here due to the   throwing of an IllegalArgumentException above). 
//  takes place 
//  their .next file during startup, and will find the next config and join it 
//  Add child watch 
//  Make sure we can instantiate a trust manager from the PKCS12 file on disk 
//  Lock object that guard access to quorumVerifier and lastSeenQuorumVerifier. 
/*          * id contains the tag for acks, and zxid for notifications          */
//  combine local and global sessions, getting local first so upgrades   to global are caught 
//  is client_config a host:port or just a port 
//  Arrange   Create a HostProvider with a list of unresolved server address(es) 
//  (*) setting it to what it should be 
//  ignores its connectstring, and next() always returns localhost:2181   it will count down when updateServerList() is called 
/*  Send close connection packet to the client, doIO will eventually     * close the underlying machinery (like socket, selectorkey, etc...)      */
// volatile int round = 1; 
/*      * Protocol identifier used among peers      */
//  Server 0 stays down 
//  See ZOOKEEPER-2967 for more details 
//  we expect this to throw an IOException since we're faking socket connect errors every time 
//  If we've timed out, do a hard shutdown 
//  see a disconnect for each Assert.failed connection attempt 
//  Pending sync requests. Must access under 'this' lock. 
//  they will be handled in next connection or cleared up if closed. 
//  start with an initial set of candidates that are voters from new config that    acknowledged the reconfig op (there must be a quorum). Choose one of them as  
//  Set up bogus streams 
//  Set to true when connected to a quorum server in read-only mode 
//  With local session on 
//  This was added to avoid running into the problem of ZOOKEEPER-1539 
//  remove host number 0 (the first one in the current list) 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorManager#     * setDefaultNodeViewerConfiguration(java.io.File, java.util.List)      */
//  We send DIFF to (2, 0) and forward any packet starting at (2, 0) 
//  Assuming that isConnected() is only used to initiate connection,   not used by some other connection status judgement. 
//  6. wait for the leader to quit due to not enough followers and come back up as a part of the new quorum 
//  Here peerCommunicationAddress is null, also clientAddr is null 
//  Test a hostname that resolves to multiple addresses 
//  pzxid not updated with smaller zxid 
/*          * epoch of the proposed leader          */
//         response.setContentType("text/plain;charset=utf-8"); 
//  not reg so should = 0 
/*      * (non-Javadoc)     *     * @see org.apache.zookeeper.server.ServerCnxnIface#process(org.apache.zookeeper.proto.WatcherEvent)      */
//  quorum.auth.learnerRequireSasl=true, quorum.auth.serverRequireSasl=true 
//  we throw an exception otherwise we continue without authentication. 
//  e.g. serviceHostname := "myhost.foo.com" 
//  Shutdown every one else but the leader 
//  This is expected. 
//  Create dummy txn larger than preAllocSize 
//  setowner as the leader itself, unless updated   via the follower handlers 
//  resume poor fellow 
// Reset back to default. 
/*      * Record leader election time      */
//  wait to connect to one of these 
//  any arbitrary constant will do  
//  Observer asks for epoch (mocking LearnerHandler behavior) 
//  TODO: should depend on zoo.cfg specified mechs, but if
//  Global session 
//  Wait until we can't connect 
//  Otherwise, wait for a fixed amount of time 
// force server to restart and load from snapshot, not txn log 
//  We use an instance of SyncedLearnerTracker to   track synced learners to make sure we still have a   quorum of current (and potentially next pending) view. 
//  NOTE: wrong password ('test' != 'test1') : this is to test SASL authentication failure.
//  creating the subtree for chRoot clients. 
//  When there is no worker thread pool, do the work directly   and wait for its completion 
//  OOM condition; 
/*              * This replica might still believe that the connection to sid is             * up, so we have to shut down the workers before trying to open a             * new connection.              */
//  On initial connection, write the complete connect request   packet, but then disable further writes until after   receiving a successful connection response.  If the   session is expired, then the server sends the expiration   response and immediately closes its end of the socket.  If   the client is simultaneously writing on its end, then the   TCP stack may choose to abort with RST, in which case the   client would never receive the session expired event.  See   http://docs.oracle.com/javase/6/docs/technotes/guides/net/articles/connection_release.html 
//  not), and all server SASL messages have been received. 
//  In this scenario to change 3's role to participant we need to remove it first 
//  Verify each quorum peer has expected quorum member view. 
//  Initialize the client's communications with the Zookeeper server by sending the server the first 
//  ipMap is used to limit connections per IP 
//  This could be faster, but probably wont be used 
//  good message 
// Thread.sleep(10000); 
//  Given ... 
//  We need to check if we can close the session id.   Sometimes the corresponding ServerCnxnFactory could be null because   we are just playing diffs from the leader. 
//  http://docs.oracle.com/javase/6/docs/technotes/guides/security/jgss/jgss-features.html   """   In addition, when performing operations as a   particular   Subject, e.g. Subject.doAs(...) or   Subject.doAsPrivileged(...), the to-be-used   GSSCredential should be added to Subject's   private credential set. Otherwise, the GSS operations   will fail since no credential is found.   """
//  Send the snapshot we created earlier 
/*      * (non-Javadoc)     *      * @see java.awt.datatransfer.Transferable#getTransferDataFlavors()      */
//  validate CRC 
//  Don't apply any prior change records less than firstZxid.   Note that previous outstanding requests might have been removed   once they are completed. 
//  verifying that other path data watches are removed 
//     make sure everything is consistent 
//  we're good. 
//  5. on the customized leader catch the beginSnapshot call in      LearnerSnapshotThrottler to set the node to value v2, 
//  Act & Assert 
/*          * Add sid to payload          */
//  represents protocol version (in other words - message type) 
/*          * (non-Javadoc)         *         * @see org.apache.zookeeper.server.RequestProcessor#shutdown()          */
// taken care in finally block 
//  cnxns typically have many watches, so use default cap here 
//  intentionally use the wrong password 
//  We send DIFF and forward any packet starting at lastProcessedZxid 
//  ensure that server and data bean are registered 
// Give it some time to process the snap  No Snapshot taken yet, the SNAP was applied in memory 
//  mySocket.setSoTimeout(20000); 
//  No event ready to emit yet. 
//  suite setup 
//  Note: The first call to getSocket() triggers mode detection which can block 
//  jute toString is horrible, remove unnecessary newlines 
//  Get the ack of the new leader 
//  watchers2 
//  list of all the followers 
//  A period that isn't on its own is ok 
//  servers in the new list that are not in the old list 
//  Validate the provided znode path contains the given watcher of   watcherType 
//  leader calls waitForNewLeaderAck, first add to ackSet 
//  non-GSSAPI: no final packet from server. 
//  Through the magic of byte buffers, txn will not be   pointing 
//  We need to sync and get consensus on any transactions 
/*      * (non-Javadoc)     *      * @seejava.awt.datatransfer.Transferable#isDataFlavorSupported(java.awt.     * datatransfer.DataFlavor)      */
//  we are setting the bytes quota 
//  check set 
//  Remove beans which are related to zk client sessions. Strong   assertions cannot be done for these client sessions because   registeration of these beans with server will happen only on their 
//  my server is not in new config, and load on old servers must   be decreased, so connect to   one of the new servers 
//  of zxid on the second log 
//  on the lookout for timeout 
// new configuration 
//  expected behaviour 
//  We expect leader to lose quorum of proposed config and time out 
//  Remove ReplicatedServer_1 from the ensemble 
//  Intercept when startForwarding is called 
//  Attempt an incremental reconfig. 
//  wait for the node to appear 
//  Verify that the exit code is set properly 
//  register, createConnection 
//  We should get snap, we can do better here, but the main logic is   that we should never send diff if we have never seen any txn older 
//  now verify autocreate off works 
//  sets reconfigMode 
//  in sync request processor get flush to disk 
//  If lost the challenge, then drop the new connection 
// start and add 2 followers 
//  don't keep this up too long, will Assert.assert false below 
//  fake the message 
//  create keytab 
//  do nothing, just return, it is the same as packet is dropped   by the network 
//  kill peer and wait no more than 5 seconds for read-only server 
//  If we are sending the first packet, figure out whether to trunc 
//  Ignore. 
//  not used. 
//  Step time 
//  during first iteration, leavingIndex will correspond to a follower 
//  Create some additional znodes without taking a snapshot afterwards. 
//  Note that 'Configuration' here refers to javax.security.auth.login.Configuration. 
/*  Log the number of fds used before and after a test is run. Verifies         * we are freeing resources correctly. Unfortunately this only works         * on unix systems (the only place sun has implemented as part of the         * mgmt bean api).          */
//  keep findbugs happy 
// turnOffFollowers(); 
//  The exception is thrown on the server side, we need to unwrap it
//  spin up a quorum, we use a small ticktime to make the test run faster 
//  default not registered 
//  The leader didn't get a quorum of acks - make sure that leader's current epoch is not advanced 
//  Timeout of 0 is not allowed, since an infinite timeout can permanently lock up an   accept() thread. 
//  It should fail and shouldn't change outstanding record.
//  leader. This should also fail 
//  The created ephemeral nodes are still around. 
//  simulate snapshot file 
//  make sure to snapshot, so that we have something there when 
//  make sure to map negative ids as well to [0, size-1] 
//  if a log file is more recent we must scan it to find   the highest zxid 
//  Allow subclasses (e.g. StatCommand) to specify their own names 
//  later packet will be notified. 
//  returns whether we are interested in taking new requests, which is 
//  Starts listener thread that waits for connection requests 
//  Observers are currently only compatible with LeaderElection 
/*          * Do not consider groups with weight zero          */
//  On Java 8, prefer CBC ciphers since AES-NI support is lacking and GCM is slower than CBC. 
//  this is good 
//  NIO should not accept conenctions 
//  Let's grab two ports 
// invalid dataversion no 
//  Notification probe = recvqueue.peek(); 
//  Need to process local session requests 
//  the version of this quorumVerifier will be set by leader.lead() in case   the leader is just being established. waitForEpochAck makes sure that readyToStart is true if 
//  Now the resulting ensemble shouldn't be quorate          
//  id but different role / port 
//  old client session can expire, restart it 
//  the pointer to the connection in the request 
/*      * This method is called when a client passes authentication data for this     * scheme. The authData is directly from the authentication packet. The     * implementor may attach new ids to the authInfo field of cnxn or may use     * cnxn to send packets back to the client.     *      * @param cnxn     *                the cnxn that received the authentication information.     * @param authData     *                the authentication data received.     * @return TODO      */
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorManager#addWatchers     * (java.util.Collection,     * org.apache.zookeeper.inspector.manager.NodeListener)      */
//  If we've already starting sending the first packet, we better finish 
//  Connect the client after services are restarted (otherwise we would get 
//  Send the packet of death 
// stored files is the list of files greater than  the zxid we are looking for. 
//  needed by jersey 
//  Get zxid of create requests 
/*      * (non-Javadoc)     *      * @see java.lang.Object#equals(java.lang.Object)      */
// setup servers 1-5 to be followers 
// Snapshot was never taken during very simple sync 
/*  PASS  */
//  now check if its the limit node 
//  It is important that this is done before the leader executes waitForEpochAck,   so before LearnerHandlers return from their waitForEpochAck   hence before they construct the NEWLEADER message containing   the last-seen-quorumverifier of the leader, which we change below 
//  Read the length, now get the buffer 
//  Arrange 
//  As above, but don't do the throttled read. Make the request bytes wait in the socket 
//  check that there's no reconfig in progress 
//  making sure setdata works on / 
//  do one successful operation on the newly added node 
//  second iteration of the loop will remove the leader 
//  allow the clients to run for max 5sec 
//  optimization for read heavy workloads   iff this is a read, and there are no pending   flushes (writes), then just pass this to the next   processor 
//  With local session off 
//  The follower reconfiguration will have failed 
//  This test makes sure that client-initiated TLS renegotiation does not 
//  Default case 
//  we're sending the designated leader, and if the leader is changing the followers are    responsible for closing the connection - this way we are sure that at least a majority of them  
//  simulate reconfig in progress - servers 0..2 have a temp reconfig 
//  Don't forward local sessions to the leader. 
//  Start thread that waits for connection requests from 
//  proposedRefresh is too far in the future: it's after ticket expires: simply return now. 
//  proceeds correctly after this point 
//  enable Client Sasl 
//  Number of machines stayed the same, my server is in the new cluster 
//  Create a couple of nodes 
//  this is the backwardCompatibility mode for no version information 
//  This is just an arbitrary object to represent requests issued by   (aka owned by) this class 
//  Something is wrong.
//  Create 10,000 nodes. This should ensure the length of our 
/*                  * A real zookeeper would take care of setting the current vote. Here                 * we do it manually.                  */
//  Create some ephemeral nodes.  This should force the session to 
//  otherwise : is at the end of the string, ignore 
//  Sleep since writing the config files may take time. 
//  this call shouldn't trigger any error or watch 
/*                              * I'm done so joining.                               */
//  Trying to load a JKS file with PEM loader should fail 
//  now update if the path is in a quota subtree. 
//  Builds an OCSPHandler that responds with a good status for all certificates   except revokedCert. 
//  We've found the priming-packet. Move it to the beginning of the queue. 
//  Will be fixed in next Kerby version.
//  We send DIFF and forward any packet starting lastProcessedZxid 
//  '/multi' should never have been created as entire op should fail 
//  Test that data provided when  
//  start of next request 
//  Negative value not allowed, will return the default 
// Follower counter 
//  /foo/bar childwatch   /foo 
/*      * We sort leader offers by sequence number (which may not be zero-based or     * contiguous) and keep their paths handy for setting watches.      */
//  make sure it doesn't have the new value that it alone had logged 
//  update last committed quorum verifier, write the new config to disk 
//  it by a commit packet 
//  We also use the sessionlessCnxnTimeout as expiring interval for   cnxnExpiryQueue. These don't need to be the same, but the expiring   interval passed into the ExpiryQueue() constructor below should be   less than or equal to the timeout. 
//  Either client is not configured to use a tunnelled authentication   scheme, or tunnelled authentication has completed (successfully or 
//  Remove the buffers that we have sent 
//  by default create snap/log dirs, but otherwise complain instead 
//  snapCount must be 2 or more. See org.apache.zookeeper.server.SyncRequestProcessor 
/*  borrowed from Path.WINDOWS  */
/*  * This code is originally from HDFS, see the file name MiniKdc there * in case of bug fixing, history, etc. * * Branch : trunk * Github Revision: 916140604ffef59466ba30832478311d3e6249bd  */
//  verify the session existence 
//  for cmds. They are all 4-bytes which fits inside of an int 
//  We are adding two new servers to the ensemble. These two servers should have the config which includes   all five servers (the old three servers, plus the two servers added). The old three servers should only   have the old three server config, because disabling reconfig will prevent synchronizing configs between   peers. 
// Make sure that we did take the snapshot now 
//  OP_READ means "can read", but OP_WRITE means "cannot write",   it's weird. 
//  LOG.info("starting forward for "+toClose); 
//  "zookeeper.server.realm" is set). 
//  7. start follower A to do snapshot sync 
//  Add ReplicatedServer_1 back to the ensemble 
//  call command and put result in byteStream 
//  remove self as it is local bean 
//  Only do extra logging so we know what kind of session this is   if we're supporting both kinds of sessions 
//  We will send DIFF for this kind of zxid in any case. This if-block   is the catch when our history older than learner and there is   no new txn since then. So we need an empty diff 
//  Restart leader election 
//  by waiting for the callback we're assured that the event queue is flushed 
//  commit proposals in order 
//  Peer have some proposals that the leader hasn't seen yet   it may used to be a leader 
// corrupt all the snapshot in the snapshot directory 
//  should work 
//  -4 is the xid for AuthPacket                
/*          * Message type: 0 notification, 1 acknowledgement          */
//  start 3 servers 
//  wait until followers time out in waitForEpochAck - they shouldn't return 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#     * getNumChildren(java.lang.String)      */
//  set the snap count to something low so that we force log rollover   and verify that is working as part of the epoch rollover. 
//  close wasn't successful, try to delete the tmp file 
//  now verify that the FileTxnLog reads every transaction only once 
//  generate some transactions 
/*  * We suppress the "try" warning here because the close() method's signature * allows it to throw InterruptedException which is strongly advised against * by AutoCloseable (see: http://docs.oracle.com/javase/7/docs/api/java/lang/AutoCloseable.html#close()). * close() will never throw an InterruptedException but the exception remains in the * signature for backwards compatibility purposes. */
//  password is test 
/*      * Connection time out value in milliseconds      */
//  Wait until we can connect 
//  make sure that ops are committed in order. With reconfigurations it is now possible   that different operations wait for different sets of acks, and we still want to enforce   that they are committed in order. Currently we only permit one outstanding reconfiguration   such that the reconfiguration and subsequent outstanding ops proposed while the reconfig is   pending all wait for a quorum of old and new config, so it's not possible to get enough acks   for an operation without getting enough acks for preceding ops. But in the future if multiple 
/*      * Turn each child of rootNodeName into a leader offer. This is a tuple of     * the sequence number and the node name.      */
//  New contents replace original file 
// LOG.info("Created a new client: " + zk.describeCNXN()); 
//  Sleeps on receive 
//  Add the root logger to the Hierarchy MBean   org.apache.log4j.Logger rootLogger = 
//  This is only true because we're setting cmdName to the primary name 
//  If we have written more than we have previously preallocated we need to make sure the new   file size is larger than what we already have 
//  create top level znode 
//  Peer is already sync 
//  resetting watcher so that this watcher can be again used to ensure   that the zkClient is able to re-establish connection with the 
//  canonicalize authorization id according to system properties:   zookeeper.kerberos.removeRealmFromPrincipal(={true,false})   zookeeper.kerberos.removeHostFromPrincipal(={true,false}) 
//  OK, expected that 
//  we failed on the most recent snapshot   must be incomplete   try reading the next one   after corrupting 
//  leader calls waitForEpochAck, first add to electingFollowers 
//  Get a three server quorum. 
//  cleanup 
/*      * (non-Javadoc)     *      * @see     * java.awt.datatransfer.Transferable#getTransferData(java.awt.datatransfer     * .DataFlavor)      */
//  We are requesting half the number of transaction from the snapshot 
//  entry point for quorum/Learner.java 
/*                          * Before joining an established ensemble, verify that                         * a majority are following the same leader.                          */
//  Errors are okay, since hosts may be   down 
//  bad gateway
//  Got a EOF right away, definitely not using TLS. Fallthrough. 
//  Check that new dynamic config includes the updated client port.   Check that server changedServerId erased clientPort from static config.   Check that other servers still have clientPort in static config. 
//  Only update pzxid when the zxid is larger than the current pzxid,   otherwise we might override higher pzxid set by a following create    Txn, which could cause the cversion and pzxid inconsistent
//  truncateLog reloads the db 
//  Set threshold to -1, as after the first commit it takes 0ms to commit to disk. 
/*                      * Set the state of the peer to LOOKING and look for leader                      */
//  this is ok - the leader has dropped leadership 
//  If unable to pull a new connection off the accept   queue, pause accepting to give us time to free   up file descriptors and so the accept thread   doesn't spin in a tight loop. 
//  Make sure that the magic number is written before padding. 
//  Must be Java 9 or later 
//  this means that the file has ended   we should go to the next file 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorManager#     * loadNodeViewersFile(java.io.File)      */
//  If sasl is not required, when a server initializes a   connection it will try to log in, but it will also   accept connections that do not start with a sasl
//  We cannot send TRUNC that cross epoch boundary.   The learner will crash if it is asked to do so.   We will send snapshot this those cases. 
//  Since the SASL authenticator will usually be used with Kerberos authentication,   it should enforce that these names are valid according to Kerberos's   syntax for principals.     Use the KerberosName(id) constructor to define validity:   if KerberosName(id) throws IllegalArgumentException, then id is invalid.   otherwise, it is valid.   
//  it does not commit ops after committing the reconfig 
//  This is safe inside an iterator as per   http://download.oracle.com/javase/1.5.0/docs/api/java/util/Map.Entry.html 
//  as a result of the I/O operations we just performed. 
//  find the leader 
//  as we look through proposals, this variable keeps track of previous   proposal Id. 
//  Max number of toasters for the sceen 
//  need it for calloc() & free() 
//  receive the commit message. 
//  for no such child 
//  Great this is what we were hoping for! 
/*      * ZOOKEEPER-2693: test white list of four letter words.     * For 3.5.x default white list is empty. Verify that is     * the case (except 'stat' command which is enabled in ClientBase     * which other tests depend on.).      */
//  disconnected 
//  ZOOKEEPER-2743:   Always unregister connection upon close to prevent   connection bean leak under certain race conditions. 
//  2. SASL login failed. 
//  null if factory never started 
//  ignore for this test 
//  All zxid should match what we created 
//  This class holds the servers and clients for those servers 
/*          * Adds up weights per group          */
//  qcm outside QV_LOCK to avoid a deadlock against other callers of qcm.connectOne(). 
//  If quorumpeer learner is not auth enabled then self won't be able to   join quorum. So this condition is ensuring that the quorumpeer learner 
//  Read without sending data. Verify timeout. 
//  ignore, we've simply come to the end of the file 
//  Receive and handle the connection request   asynchronously if the quorum sasl authentication is   enabled. This is required because sasl server   authentication process may take few seconds to finish,   this may delay next peer connection requests. 
/*      * Separated this method from the main run loop     * for test purposes (ZOOKEEPER-1863)      */
//  rewrite to option 
//  LoginThread will sleep until 80% of time from last refresh to   ticket's expiry has been reached, at which time it will wake 
/*          * Used to send a QuorumVerifier (configuration info)          */
/*                              * Print notification info                              */
//  new server 3 has still its invalid joiner config - everyone in old 
//  Commit /foo1 update 
//  create child znodes 
//  Note: getting the input stream should not block the thread or trigger mode detection.
//  mapping was present, clean up the previous expiry bucket. 
//  We can get here, if we don't have op packet to queue   or there is a duplicate txn in a given iterator 
//  We only want to print anything if things have had a   chance to change 
//  to removed server 
//  We can't call outgoingQueue.clear() here because   between iterating and clear up there might be new   packets added in queuePacket(). 
//  don't re-establish connection if we are closing 
//  Start the servers with a static config file, without a dynamic 
//  Find zxid for the second log 
//  crank up the epoch numbers 
// "This should never happen, you can't have a filter exception without a filter"); 
//  All new sessions local by default. 
//  handle clientPath = "/" 
//  2. set force snapshot to be true 
//  Nothing to do, we are shutting things down, so an exception here is irrelevant 
//  free the error stream buffer 
/*          * If sending message to myself, then simply enqueue it (loopback).          */
/*                  * Choose identifier at random. We need a value to identify                 * the connection.                  */
//  entry point for FinalRequestProcessor.java 
//  closing session should remove ephemeral nodes and trigger data   watches if any 
//  stopping the ELECTED node, so re-election will happen. 
//  We expect this to happen. 
// return "    "+capitalize(fname)+"=a_.Read"+mMethodSuffix+"(" + capitalize(fname) + ",\""+tag+"\");\n"; 
//  Show time 
//  listener thread should stop and throws error which notify QuorumPeer about error.   QuorumPeer should start shutdown process   set wait time, if listener contains bug and thread not stops. 
// LOG.warn("ClientParts: " + serverClientParts[1]); 
//  some tests initialize QuorumPeer without a static config file 
// zk.close(); 
//  Setting used for snapRetainCount in this test. 
//  NIOServerCnxnFactory 
/*          * Update the election vote here to ensure that all members of the         * ensemble report the same vote to new servers that start up and         * send leader election notifications to the ensemble.         *          * @see https://issues.apache.org/jira/browse/ZOOKEEPER-1732          */
//  subject is non-null, it can be assumed to be GSSAPI. 
//  Should be able to dump the recovered logfile with no CRC error 
//  check content of transaction log and snapshot dirs if they are two different directories 
//  Run the command 
//  Sending id and challenge 
//  assume that server and client are in the same realm (by default;   unless the system property 
/*      * Messages to send, both Notifications and Acks      */
//  resolution occured every time 
//  ignore "/" chroot spec, same as null 
//  This was added in ZOOKEEPER-1783. The initial config has version 0 (not explicitly   specified by the user; the lack of version in a config file is interpreted as version=0).    As soon as a config is established we would like to increase its version so that it   takes presedence over other initial configs that were not established (such as a config   of a server trying to join the ensemble, which may be a partial view of the system, not the full config).    We chose to set the new version to the one of the NEWLEADER message. However, before we can do that   there must be agreement on the new version, so we can only change the version when sending/receiving UPTODATE,   not when sending/receiving NEWLEADER. In other words, we can't change curQV here since its the committed quorum verifier,    and there's still no agreement on the new version that we'd like to use. Instead, we use    lastSeenQuorumVerifier which is being sent with NEWLEADER message   so its a good way to let followers know about the new version. (The original reason for sending    lastSeenQuorumVerifier with NEWLEADER is so that the leader completes any potentially uncommitted reconfigs   that it finds before starting to propose operations. Here we're reusing the same code path for    reaching consensus on the new version number.) 
//  Clean up for shutdown. 
//  just make sure that we actually did get it in process at the   leader 
//  remove the error 
//  Create a file at destination 
//  make sure we don't mess with request itself 
/*  if we are not truncating or sending a diff just send a snapshot  */
//  send a response... 
//  Start peer0,1,2 servers with quorum.auth.enableSasl=false and   quorum.auth.learnerRequireSasl=false, quorum.auth.serverRequireSasl=false 
//  Set sizeLimit to be very high number, so we can pull all transactions 
//  response as with other packets. 
//  Multiply by 1000 to get   reqs/sec 
//  initial data is written. 
//  We want to queue the request to be processed before we submit   the request to the leader so that we are ready to receive 
//  add back host number 0 
//  Make sure we can instantiate a trust manager from the PEM file on disk 
//  0xff = Extended feature is ON   0x0001 = Unsupported extended type id (1) 
//  Explicitly add to global session if the flag is not set 
//  request.addRQRec(">final"); 
//  the files   are sorted with zxid's 
//  If the connection is not in the master list it's already been closed 
/*  this 'Client' section has the correct password, but we're not configured                                  to  use it (we're configured by the above System.setProperty(...LOGIN_CONTEXT_NAME_KEY...) to                                   use the 'MyZookeeperClient' section, which has an incorrect password). */
//  parse the output   clear the input stream buffer 
//  check for more than 2 children --   if zookeeper_stats and zookeeper_quotas   are not the children then this path   is an ancestor of some path that 
//  quorum.auth.learnerRequireSasl=false, quorum.auth.serverRequireSasl=false 
//  Wait for falseLeader to rejoin the quorum 
//  parent channel options 
//  Validate status code at the end of authentication exchange. 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorManager#disconnect()      */
//  *************** <END> CientCnxnSocketNetty </END> ****************** 
//  Otherwise proceed with the connection 
//  input buffer until after throttling is turned off. Need to make sure both modes work. 
//  check exceptions 
//  Find the leader by id 
//  For Invalid ACls should not throw exception 
//  create child to see NodeChildren notification 
//     private void notestConnections()          throws IOException, InterruptedException, KeeperException      {          ZooKeeper zk; 
//  found path watchers 
//  the sleep is necessary so that the leader figures out 
//  sanity check 
/*      * Methods to aid in testing follow.     *      * THESE METHODS ARE EXPECTED TO BE USED FOR TESTING ONLY!!!      */
//  Use subject.getPrincipals().isEmpty() as an indication of which SASL   mechanism to use: if empty, use DIGEST-MD5; otherwise, use GSSAPI. 
/*  new client port  */
//  Animate from top! 
//  DIFF + 2 proposals + 2 commit 
//  Generate snapshot and close files. 
//  create with valid sequential flag 
//  Check whether it's a global session. We can ignore those   because they are handled at the leader, but if not, rethrow.   We check local session status first to avoid race condition   with session upgrading. 
//  add all non-excluded log files 
//  test the most likely situation only: server is stated as observer in 
//  iterator points to   the first valid txn when initialized 
//  delete 
/*          * Requests coming from the learner should have gone through         * submitRequest() on each server which already perform some request         * validation, so we don't need to do it again.         *         * Additionally, LearnerHandler should start submitting requests into         * the leader's pipeline only when the leader's server is started, so we         * can submit the request directly into PrepRequestProcessor.         *         * This is done so that requests from learners won't go through         * LeaderRequestProcessor which perform local session upgrade.          */
/*                  * It is possible that committedLog is empty. In that case                 * setting these value to the latest txn in leader db                 * will reduce the case that we need to handle                 *                 * Here is how each case handle by the if block below                 * 1. lastProcessZxid == peerZxid -> Handle by (2)                 * 2. lastProcessZxid < peerZxid -> Handle by (3)                 * 3. lastProcessZxid > peerZxid -> Handle by (5)                  */
//  Peer zxid 
//  Grab a list iterator starting at the END of the list so we can iterate in reverse 
//  0 value not allowed, will return the default 
//  Test view contains self 
//  Wait until all updates return 
//  log request 
//  Make sure the data was recorded in the filesystem ok 
//  Child watcher 
//  Now, try an ephemeral node.  This should fail since we 
//  stop all severs 
//  ZOOKEEPER-2722: wait until we can connect to a read-write server after the quorum   is formed. Otherwise, it is possible that client first connects to a read-only server,   then drops the connection because of shutting down of the read-only server caused   by leader election / quorum forming between the read-only server and the newly started   server. If we happen to execute the zk.create after the read-only server is shutdown and   before the quorum is formed, we will get a ConnectLossException. 
//  If an exception occurred we misdetected a sequence suffix,   so return -1. 
//  double check for the file existence 
//  We now ship the request to the leader. As with all   other quorum operations, sync also follows this code   path, but different from others, we need to keep track   of the sync operations this follower has pending, so we 
/*              * Now we start a new connection              */
//  TODO: introduce JuteTestCase as in ZKTestCase 
// there should be only two files   one the snapshot and the other logFile 
//  now corrupt the leader's database 
//  flush the config to server 2 
//  fake messages from the server 
//  Put the new set in the map, but only if another thread 
/*                          * Consider all notifications from the same epoch                         * together.                          */
//  this is a test that a reconfig will only succeed   if there is a quorum up in new config. Below there is no   quorum so it should fail 
//  simulate the upgrading case where the config node will be created 
/*  this 'Client' section has an incorrect password, but we're not configured                                  to  use it (we're configured by the above System.setProperty(...LOGIN_CONTEXT_NAME_KEY...) to                                   use the 'MyZookeeperClient' section below, which has the correct password). */
//  call is no-op if session isn't tracked so safe to call both 
//  Need to be short since we need to wait for session to expire 
// 1. Upgrade peer0,1,2 with quorum.auth.enableSasl=true and 
//  It would be great to test the value of PKIXBuilderParameters#setRevocationEnabled but it does not appear to be 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorManager#     * getConnectionPropertiesTemplate()      */
//  If this request is the commit request that was blocking   the processor, clear. 
//  wait for selector and worker threads to shutdown 
//  Reset to default value since some test cases set this to true.   Needed for JDK7 since unit test can run is random order 
/*          * Address of recipient          */
//  never true if tmpfile does it's job 
/*              * Note that addAck already checks that the learner             * is a PARTICIPANT.              */
//  this server will be added back as an observer 
//  ... and finally disable throttling after 2 seconds. 
// All the rest don't need to create a Txn - just verify session 
//  we've asked to close, wait for it to finish closing   all the sub-threads otw the selector may not be   closed when we check (false positive on test Assert.failure 
//  only use jline if it's in the classpath 
//  don't try to handle jersey exceptions ourselves 
//  ulimit isn't supported on Windows
//  get new designated leader from (current) leader's message 
/*  this 'Server' section has an incorrect password, but we're not configured         * to  use it (we're configured by the above System.setProperty(...LOGIN_CONTEXT_NAME_KEY...)         * to use the 'MyZookeeperServer' section below, which has the correct password).          */
//  c.f. HADOOP-6559 
//  close clients 
//  start creating all the parents 
//  this data structure must be accessed under the outstandingChanges lock 
//  go through buffer until i find a \n, if i reach end of buffer first, put whats in buffer into string buffer,   repeat 
/*                      * A real zookeeper would take care of setting the current vote. Here                     * we do it manually.                      */
//  we should catch the exceptions   from the valid snapshot and continue   until we find a valid one 
//  Cannot use createClient here because server may close session before    JMXEnv.ensureAll is called which will fail the test case 
//  lastProcessedZxid 
//  nothing interesting to do if out == null 
//  transaction log and snapshot files in the same dir 
//  observer calls waitForEpochAck, should fail verifier.containsQuorum 
//  Trying to get a second txn on second txnlog give us the 
/*  some useful information - log the number of fds used before         * and after a test is run. Helps to verify we are freeing resources         * correctly. Unfortunately this only works on unix systems (the         * only place sun has implemented as part of the mgmt bean api.          */
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.encryption.DataEncryptionManager#encryptData     * (java.lang.String)      */
/*              * Here are the cases that we want to handle             *             * 1. Force sending snapshot (for testing purpose)             * 2. Peer and leader is already sync, send empty diff             * 3. Follower has txn that we haven't seen. This may be old leader             *    so we need to send TRUNC. However, if peer has newEpochZxid,             *    we cannot send TRUNC since the follower has no txnlog             * 4. Follower is within committedLog range or already in-sync.             *    We may need to send DIFF or TRUNC depending on follower's zxid             *    We always send empty DIFF if follower is already in-sync             * 5. Follower missed the committedLog. We will try to use on-disk             *    txnlog + committedLog to sync with follower. If that fail,             *    we will send snapshot              */
//  my server is in new config, and load should be increased, so   stay with this server and do nothing special 
// the transaction logs 
//  Set the last accepted epoch and current epochs to be 1 
/*          * Proposed leader in the case of notification          */
//  visiable for test 
//  Purge snapshot and log files. 
//  e.g. servicePrincipalNameAndHostname := 
//  for now. 
//  Take any necessary action if we need to send TRUNC or DIFF 
//  'domain' parameter is hard-wired between the server and client 
/*  this is ok  */
//     txn proposal and commit for v1 value update 
/*          * When a new leader starts executing Leader#lead, it          * invokes this method. The database, however, has been         * initialized before running leader election so that         * the server could pick its zxid for its initial vote.         * It does it by invoking QuorumPeer#getLastLoggedZxid.         * Consequently, we don't need to initialize it once more         * and avoid the penalty of loading it a second time. Not          * reloading it is particularly important for applications         * that host a large database.         *          * The following if block checks whether the database has         * been initialized or not. Note that this method is         * invoked by at least one other method:          * ZooKeeperServer#startdata.         *           * See ZOOKEEPER-1642 for more detail.          */
//  Depricated: rmr 
//  server error or shutdown state changes. 
/*                  * For future unwary socket programmers: although connect 'blocks' it                 * does not require an accept on the server side to return. Therefore                 * you can not assume that all the sockets are connected at the end of                 * this for loop.                  */
/*          * zxid of the proposed leader          */
//  / marks end of stream   we need to check if clear had been called in between the snapshot. 
//  Ensure we have the leader's correct IP address before   attempting to connect. 
//  this should break the run() loop 
//  LOG.info("Prep>>> cxid = " + request.cxid + " type = " + 
//  LOG.warn("sid = " + sid + " addressStr = " + addressStr); 
//  case-1) 'quorum.auth.enableSasl' is off. Tries to enable learner sasl. 
//  ZOOKEEPER-2819: overwrite config node content extracted   from leader snapshot with local config, to avoid potential 
//  All dynamic files created with the same version should have 
//  Creating child using chRoot client. 
//  Send the valid or invalid session packet to the follower 
/*              * Do the flip: limit becomes position, position gets set to             * 0. This sets us up for the write.              */
//  wildCard address(0.0.0.0)   loopback address(localhost/127.0.0.1) 
//  transaction log files in log dir 
//  Make tracked buffers eligible for GC 
// deserialize a DataTree; this should clear the old /bug nodes and pathTrie 
//  now, truncate at the current position 
//  upgrade this once we have Google-Guava or Java 7+ 
//  Should be noop 
//  when we do the Cversion we need to translate from the count of the creates   to the count of the changes (v3 semantics)   for every create there is a delete except for the children still present 
// This will fast forward the database to the latest recorded transactions 
//  Original contents still in place 
/*          * Format version, introduced in 3.4.6          */
//  same port. 
//  capture QuorumPeer logging 
//  verify that the size is just 2 - ie connect then disconnect   if the client attempts reconnect and we are not handling current   state correctly (ie eventing on duplicate disconnects) then we'll 
//  catch this. 
//  now shut down the servers and restart them 
//  create dummy log and transaction file 
//  Register watch 
//  /10 wont work because the session expiration   will match the zxid for /10 and so we wont   actually truncate the zxid for /10 creation   due to an artifact of switching the xid of the standalone   /11 is the last entry in the log for the xid   as a result /12 is the first of the truncated znodes to check for
// } 
//  Make sure that previous request is finished 
//  TODO lets assert that we are no longer the leader 
//  Recreate a client session since the previous session was not persisted. 
//  for them that a reconfiguration was in progress when they failed 
//  Calling closeSession() after losing the cnxn, results in the client close session response being dropped. 
//  start the old leader 
//  ignore, simply end of file, though really (line!=null) should have caught this 
/*                                  * Assert that the state of the thread is the one expected.                                  */
//  get the value from the map 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#getData     * (java.lang.String)      */
//  If SASL authentication is currently in progress, construct and   send a response packet immediately, rather than queuing a 
//  specify all of the commands that are available 
// Wait for the transactions to be written out. The thread that writes them out 
//  Use gathered write call. This updates the positions of the   byte buffers to reflect the bytes that were written out. 
//  Try to load a password-protected private key without providing a password 
//  The proposal has already been committed 
//  sanitise start and end times 
/*  expected  */
//  two of the servers as observers, and all ports different 
//  if we're here, I shouldn't be the leader 
//  Use a single listener instance to reduce GC 
/*                              * We want to make sure we implement the state machine                             * correctly. If we are a PARTICIPANT, once a leader                             * is elected we can move either to LEADING or                             * FOLLOWING. However if we are an OBSERVER, it is an                             * error to be elected as a Leader.                              */
//  Try reconnecting with a new session.   The data should be persisted, even though the session was not. 
//  survives the exception thrown by the first callback. 
//  not the case for 4letterword 
//  clear all the connections 
//  giving a grace period of 10seconds 
//  Make sure we can instantiate a key manager from the JKS file on disk 
//  and add back hosts 6, 7 and 8 
//  the watch contains the un-chroot path 
//  OK, now the follower knows that the session is valid or invalid, let's try 
//  verify super with bad pass Assert.fails 
//  For global session, if we don't know it, it is already expired 
// non-incremental membership change                   
//  setup redirect out/err streams to get System.in/err, use this   judiciously!   get current err 
//  watches which require multiple SetWatches calls. 
/*  configure socket to be blocking            * so that we dont have to do write in            * a tight while loop             */
//  Start 3rd peer and check if it goes in LEADING state 
//  We are simulating an established leader, so the epoch is 1 
//  leader will shutdown, remaining followers will elect a new leader 
// / delete the direct children first 
//  have we read length bytes?   sock is non-blocking, so ok 
//  add back server 7 
//  lets try look up the current ID if we failed    in the middle of creating the znode 
//  ignore, this just means server is not up 
/*                          * we now wait until a quorum supports the same leader.                          */
/*                      * Building challenge request packet to send                      */
//  Sending a nonexisting opcode should cause the server to disconnect 
//  shutdown and start zookeeper again 
//  new server joining 
//  Server.start() only throws Exception, so let's at least wrap it   in an identifiable subclass 
//  NumberFormatException 
//  Mock processor used in zookeeper server 
//  Replace trusted keys with a valid key that is not trusted by the server 
//  do nothing for the root.   we are not keeping a quota on the zookeeper   root node for now. 
//  Set message color 
//  add all non-excluded snapshot files to the deletion list 
//  server.  This should fail since it is a local sesion.
/*              * Receives a socket and max number of attempts as input              */
//  change leader's leading port - should renounce leadership 
//  Do nothing 
//  second add to ackSet, verifier.containsQuorum=true, waitForNewLeaderAck returns without exceptions 
//  inconsistency of config node content during rolling restart. 
//  32 cores sweet spot seems to be 4 selector threads 
// This is the real assertion - could another thread lock  the DataNode we're currently writing 
//  that id 
//  Restore former value. 
//  Check that return code of all request are correct 
//  Allows the JVM to shutdown even if this thread is still running. 
//  standalone mode doens't need myid 
//  re-open the txnLog and snapLog   I'd rather just close/reopen this object itself, however that    would have a big impact outside ZKDatabase as there are other
//  Resolver called 10 times, because we shouldn't cache the resolved addresses
//  Non-priming packet: defer it until later, leaving it in the queue   until authentication completes. 
// check if I'm an observer in new config 
//  lets sort them explicitly (though they do seem to come back in order ususally :) 
//  initialization 
//  this is the limit node   get the parent and add it to the trie 
//  this is a server id and not a protocol version 
//  Hard close immediately, discarding buffers 
//  the initial message (without the protocol version) 
//  Ignore. We'll check instead whether it's a global session 
//  Check if this is a local session and we are trying to create   an ephemeral node, in which case we upgrade the session 
/*  this 'Client' section has the correct password, but we're not configured                                  to  use it - we're configured instead by the above                                  System.setProperty(...LOGIN_CONTEXT_NAME_KEY...) to                                  use the (nonexistent) 'MyZookeeperClient' section.  */
//  only happens during tests 
/*  ZOOKEEPER-706: If a session has a large number of watches set then     * attempting to re-establish those watches after a connection loss may     * fail due to the SetWatches request exceeding the server's configured     * jute.maxBuffer value. To avoid this we instead split the watch     * re-establishement across multiple SetWatches calls. This constant     * controls the size of each call. It is set to 128kB to be conservative     * with respect to the server's 1MB default for jute.maxBuffer.      */
//  server is using a JAAS-authenticated subject: determine service   principal name and hostname from zk server's subject. 
//  hasn't beaten us to it 
//  skip to the offset of latest skip point before starttime 
//  Point server at testDir 
//  Make sure that empty password and null password are treated the same 
//  create ephemeral sequential node 
//  Make all snapshots empty 
//  We keep a queue of requests. As requests get submitted they are   stored here. The queue is drained in the run() method. 
//  some of the operations will be executed by a client connected to   the removed server   while others are invoked by a client connected to some other   server.   when we're removing the leader, zk1 will be the client connected 
//  ok. 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorNodeTreeManager#createNode     * (java.lang.String, java.lang.String)      */
//  On windows, renameTo does not replace. 
//  If this is a request for a local session and it is to   create an ephemeral node, then upgrade the session and return   a new session request for the leader.   This is called by the request processor thread (either follower   or observer request processor), which is unique to a learner.   So will not be called concurrently by two threads. 
//  from txnlog 
//  warn, but generally this is ok 
//  Start the prepared thread so that it is writing znodes while   the follower is restarting. On the first restart, the follow   should use txnlog to catchup. For subsequent restart, the   follower should use a diff to catchup. 
//  take the last server to which we were connected 
//  convert to milliseconds 
//  therefore authentication is (at the earliest stage of being) in progress. 
//  wait for the process to finish and check the exit code 
/*          * Building notification packet to send          */
/*              * Lower epoch must return false              */
// we need to truncate the log to the lastzxid of the leader 
//  Send diff and fall through if zxid is of a new-epoch 
//  next two steps - related to sequential processing   1) verify that empty child name Assert.fails if not sequential 
//  Test view does not contain non-existant servers 
//  break the quorum 
//  getting called by PrepRequestProcessor 
/*                          * quora keeps the supporters of a given leader, so                          * we first update it with the vote of this peer.                          */
//  We send DIFF to (6,0) and forward any packet starting at (6, 0) 
//  register with JMX 
//  test fails if we still can't connect to the quorum after   30 seconds. 
//  Per RFC 5280 section 4.1.2.2, X509 certificates can use up to 20 bytes == 160 bits for serial numbers. 
/*          * Building notification packet to send, this is called directly only in tests          */
/*      * Normalize IPv6 or DNS name.      */
//  add child,remove child and then call getChildren 
//  First add the elem to the new expiry time bucket in expiryMap. 
//  It's possible our session expired - but this is ok, shows we  
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.gui.NodeViewersChangeListener#     * nodeViewersChanged(java.util.List)      */
//  Reconfigure 
//  If qcm is non-null, we may call qcm.connectOne(), which will take the lock on qcm   and then take QV_LOCK.  Take the locks in the same order to ensure that we don't   deadlock against other callers of connectOne().  If qcmRef gets set in another   thread while we're inside the synchronized block, that does no harm; if we didn't   take a lock on qcm (because it was null when we sampled it), we won't call   connectOne() on it.  (Use of an AtomicReference is enough to guarantee visibility   of updates that provably happen in another thread before entering this method.) 
//  sessionMap is used by closeSession() 
//  any arbitrary constant will do 
/*      * For ZOOKEEPER-975 verify that a peer joining an established cluster     * does not go in LEADING state.      */
/*         On startup, it's possible that we'll try calling addUsage of an ID not in the cache.  This is safe to ignore        as it'll be added later when we traverse the tranlog.  See discussion here:        http://mail-archives.apache.org/mod_mbox/zookeeper-user/201507.mbox/%3CCAB5oV2_ujhvBA1sEkCG2WRakPjCy%2BNR10620WK2G1GGgmEO44g%40mail.gmail.com%3E        This test makes sure that we don't add the ID to the cache in this case as that would result in dupes later        and consequently incorrect counts and entries that will never be cleaned out.          */
//  setting back 
//  should always be the case 
//  Flag that indicate if use alwaysOnTop or not. 
//  corrupt the logfile 
//  creating ephemeral with wrong option. 
//  set on watch 
// reduce the set of candidates to those that acknowledged p 
//  remember this server so we can add it back later 
//  Simulate a bit of network latency... 
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.manager.ZooInspectorNodeTreeManager#deleteNode     * (java.lang.String)      */
//  Write only 2 bytes of the message, wait a bit, then write the rest.   This makes sure that writes smaller than 5 bytes don't break the plaintext mode on the server   once it decides that the input doesn't look like a TLS handshake. 
//  call reconfig API when the new server has received 
//  Send watches packet to server connection 
//  We have to get at least a majority of servers in sync with   us. We do this by waiting for the NEWLEADER packet to get   acknowledged 
//  Pattern.compile("Notification: \\d+, (\\d+), (\\d+), \\d+, [^,]*, [^,]*, (\\d+)");//, LOOKING, LOOKING, 2 
//  Shutdown sequence guarantee that all pending requests 
//     wait it hit data tree 
//  Mimic sessionId generated by follower's local session tracker 
//  validate lower limit 
//  sets lastIndex, resets reconfigMode 
//  remove host number 8 (the last one in a list of 9 hosts) 
//  Format and print the output of the command 
//  Peer miss the txnlog 
//  Skip the xid 
//  Peer zxid is in txnlog range 
//  setup the logger to capture all logs 
//  Get expected exception 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorManager#     * getLastConnectionProps()      */
//  now start the third server so that new config has quorum 
// Check format 
//  by setting the value to 2 
//  message too long 
/*  Rather than fight it, let root have an alias  */
//  TODO only show add if a selected node isn't being   watched, and only show remove if a selected node is being   watched
//  Since we preallocate, we define EOF to be an   empty transaction 
//  now shutdown the server and restart it 
// If we are not going to take the snapshot be sure the transactions are not applied in memory 
// Keep these two lines together to keep the initialization order explicit 
// check to see if the leader zxid is lower than ours  this should never happen but is just a safety check 
//  ignore silently 
//  resolution occurred 
//  If we failed when flushing, try to close it to not leak   an FD 
/*      * Tests that if a quorum of a new config is synced with the leader and a reconfig     * is allowed to start but then the new quorum is lost, the leader will time out and     * we go to leader election.      */
//  We send DIFF to (1, 2) and forward any packet starting at (1, 2) 
/*                              * If this server is looking, then send proposed leader                              */
//  We want to track the change with a callback rather than depending on timing 
//  server_config should be either host:port:port or host:port:port:type 
//  Node 2 started last, kicks off leader election 
//  Ignore. This may be local session from other servers. 
//  lets remove someone who's not the leader 
//  get the new configuration from the request 
//  ZOOKEEPER-2693: don't execute 4lw if it's not enabled. 
//  Set SSL system properties and port unification, begin restarting servers 
//  now parse it 
/*                      * Exponential backoff                      */
//  and the leader will complete it 
/*  nThreads  */
//  setting up the quorum has a transaction overhead for creating and closing the session 
/*  Prep the request and convert to a Txn  */
//    test get/exists with two sets of watchers 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorReadOnlyManager#     * isAllowsChildren(java.lang.String)      */
/*  Once we've figured out where we are, we're done.  */
//  lets see one successful operation 
//  try to reestablish the quorum 
//  Same as for element.  Should refactor this.
//  make sure zkclient works 
//  start server 3 with new config 
//  or none, if not ready yet. Sets saslState to COMPLETE as a side-effect. 
//  Instead of starting roZk immediately, wait some grace   period before we decide we're partitioned.     Thread is used here because otherwise it would require   changes in each of election strategy classes which is 
//  This should never happen 
//  LOG.warn("Ack>>> cxid = " + request.cxid + " type = " +   request.type + " id = " + request.sessionId);   request.addRQRec(">prop"); 
//  This method can return empty iterator if the requested zxid 
//  log at error level as we are returning a marshalling   error to the user 
//  if we have read data from the file, and it matchs the timep pattern 
//  No change, so nothing to update 
//  Make sure to atomically check local session status, upgrade   session, and make the session creation request.  This is to   avoid another thread upgrading the session in parallel. 
/*      * For each leader offer, find out where we fit in. If we're first, we     * become the leader. If we're not elected the leader, attempt to stat the     * offer just less than us. If they exist, watch for their failure, but if     * they don't, become the leader.      */
//  ZOOKEEPER-3056: provides an escape hatch for users upgrading   from old versions of zookeeper (3.4.x, pre 3.5.3). 
//  the follower acceptor thread 
//  c.f. org.apache.hadoop.security.UserGroupInformation. 
//  Now kill one of the other real servers         
//  servers with authentication interfaces configured 
//  resets "zookeeper.datadir.autocreate" flag 
//  Note: mode is UNKNOWN or PLAINTEXT 
//  Disable throttling and resume acceptance of new requests. If this   entailed a state change, register an interest op update request with 
//  and add it back (as follower) 
//  create a file logger url from the command line args 
//  check delete 
//  leader 
//  Input may be delimited by either commas or newlines so convert to common newline separated format 
//  return number of session expiry calls 
//  Touch table for the global sessions 
//  watcher1 
//  init quorum auth server & learner 
//  verify bad pass Assert.fails 
//  verifying that other path child watches are not affected 
//  start 2 peers and verify if they form the cluster 
//  This server should fail to join the quorum as it is not using ssl. 
//  check if the path exists. We cannot create   quota for a path that already exists in zookeeper 
//  if no matching option -c or -d or -a is specified, we remove   the watches of the given node by choosing WatcherType.Any 
/*                                  * Version added in 3.4.6                                  */
//  we want to loop through the list twice 
//  create transaction and snapshot files in different-different 
//  set a watch on the root node 
//  the selector. 
//  Note: according to the Socket javadocs, setTrafficClass() may be   ignored by socket implementations, so we don't check that the value   we set is returned. 
//  execute from commandMap 
//  sub process used to execute the command 
//  Now participant asks for epoch (mocking LearnerHandler behavior). Second add to connectingFollowers.   Triggers verifier.containsQuorum = true 
//  that the switched off servers are down 
// LOG.warn("designated leader is: " + designatedLeader); 
/*      * Creates a leader election notification message.      */
//  we want to send our version of the request. 
//  This should be enough time for the first session to expire and for   the closeSession request to propagate to other machines (if there is a bug)   Since it is time sensitive, we have false negative when test 
//  Here we start populating the server and shutdown the follower after 
//  clear our internal buffer 
//  Access to ipMap or to any Set contained in the map needs to be   protected with synchronized (ipMap) { ... } 
//  choose "current" server according to the client rebalancing algorithm 
// create/close session don't require request record 
/*          * Start one LEThread for each peer we want to run.          */
//  Grab some memory so that it is easier to cause an 
//  Doing a delete 
//  ensure zk got connected 
//  use synchronized(this) to access 
//  Defaults ServerCnxnFactory would be instantiated with 
//  make sure there is a leader 
//  now create the direct children 
//  add back servers 7 and 8 while still in reconfigMode (we didn't call 
//  Create Zookeeper and connect to it. 
// quorumPeer.setQuorumPeers(config.getAllMembers()); 
//  we only import NodeViewers 
/*      * Challenge counter to avoid replay attacks      */
// Check that the node path is removed from pTrie 
//  including the header and the last / bytes   the snapshot should be at least 10 bytes 
//  not a CA 
//  number of entries skipped to get to the end of the iterator, less the number skipped to get to the start 
/*  save the return error code by the server  */
//  Change the '1' to e.g. 5, to change this to 5 minutes. 
//  authenticate learner 
//  The test method threw an exception, but it might be an   expected exception as defined in the @Test annotation.   Check the annotation and log an appropriate message. 
//  register an interest op update request with the selector. 
//  This must be a global request 
//  Here we create 13000 znodes 
//  The change should happen now 
/*      * Request processors      */
//  1238, 1237 
//  Create and Register the top level Log4J MBean 
//  Test basic create, ls, and getData 
//  No entries in jaas.conf   If there's a configuration exception fetching the jaas section and   the user has required sasl by specifying a LOGIN_CONTEXT_NAME_KEY or a jaas file 
//  don't waste memory if there are few watches on a node   rehash when the 4th entry is added, doubling size thereafter   seems like a good compromise 
//  creating sequential nodes is stored properly 
//  servers, and then bounce the other servers one by one 
//  than peer zxid 
//  Check that when a server starts from old style config, it should keep the client 
/*          * Send the same messages, this time should not make 0 the leader.          */
//  start additional new servers 
//  pretend each connect attempt takes 4000 milliseconds 
//  servers 4 and 5 should be able to work independently 
/*  We've sent the whole buffer, so drop the buffer  */
/*               * Start a new connection if doesn't have one already.               */
//  watcher2 
//  Send the connection request as a client do 
//  This value will be used directly in {@link CODE#SESSIONMOVED}   public static final int SessionMoved = -118;        
/*      * (non-Javadoc)     *      * @see     * org.apache.zookeeper.inspector.gui.nodeviewer.ZooInspectorNodeViewer#     * setZooInspectorManager     * (org.apache.zookeeper.inspector.manager.ZooInspectorNodeManager)      */
//  this is ok -- just a packet from an old client which   doesn't contain readOnly field 
//  Number of machines increased, my server is in the new cluster   Here whether to move or not depends on the difference of cluster   sizes   With probability 1 - |old|/|new} the client disconnects 
//  In this case, the hostname equals literal IP address. 
//  queuedBuffer has reached its component limit, so combine the existing components. 
//  check if being waken up on closing. 
//  abort if we hit the limit 
/*          * Start mock server 1          */
//  start server again with intact database 
//  so this shouldn't break anything. 
//  Resolve hostname for this server in case the   underlying ip address has changed. 
//  lets remove the leader and some other server 
//  Throw an error if there were any leaked buffers 
//  delete till you can find a node with more than   one child 
// shutdown leader- quorum should still exist 
/*      * (non-Javadoc)     *      * @seeorg.apache.zookeeper.inspector.manager.ZooInspectorManager#     * saveNodeViewersFile(java.io.File, java.util.List)      */
/*  Election instance  */
//  if no TGT, do not bother with ticket management. 
//  each watcher will process the event 
//  7. restart the previous leader to force it to replay the edits and possibly come up in a bad state 
//  shutdown 2 followers so that leader does not have majority and goes 
//  make sure they joined the new config without any change to it 
//  where the packet is actually sent. 
//  write message 
//  Get each logger from the Log4J Repository and add it to the   Hierarchy MBean created above.   org.apache.log4j.spi.LoggerRepository r = 
//  We send snap 
//  a different, larger version dynamic file 
//  Start up the ZK server to automatically create the necessary directories   and capture the directory where data is stored 
//  look for the clients to finish their create operations 
//  default constructor 
//  it later 
//  startForwarding() will be called in all cases 
// send a ping request either time is due or no packet sent out within MAX_SEND_PING_INTERVAL 
//  some of the operations will be executed by a client connected to   the removed server   while others are invoked by a client connected to some other   server.   when we're removing the leader, zk1 will be the client connected   to removed server 
//  Again, the user explicitly set something SASL-related, so   they probably expected SASL to succeed. 
//  content preserved 
//  1246, 1245, 1244, 1243, 1242, 1241, 1240, 1139 
//  check to avoid startup follows shutdown 
//  sleep for 10 millisecond and then again check 
//  check the existence of name in bean 
/*                  * When local session upgrading is disabled, leader will                 * reject the ephemeral node creation due to session expire.                 * However, if this is the follower that issue the request,                 * it will have the correct error code, so we should use that                 * and report to user                  */
//  Only called as callback from zkServer.processPacket() 
// If the test failes it will most likely fail with a NoAuth exception before it ever gets to this assertion 
//  loop through the args (must be key/value sequence) 
//  Falls back to filename detection if no property value 
//  3. start up the followers to form a new quorum 
//  Number of machines became smaller, my server is not in the new   cluster 
//     the node value is same as what we have on leader 
//  Check that the static config was split into static and dynamic files correctly. 
/*  (non-Javadoc)         * @see org.apache.zookeeper.ClientWatchManager#materialize(Event.KeeperState,          *                                                        Event.EventType, java.lang.String)          */
//  Signal for graceful shutdown 
//  proceed to the next processor 
//  do cleanup 
//  halt one of the listeners and verify count 
//  Throttle when there are too many concurrent snapshots being sent to observers 
//  should only happen during upgrade 
// check for any parent that has been quota 
//  take one of the new servers if it is possible (there are still such   servers we didn't try),   and either the probability tells us to connect to one of the new   servers or if we already   tried all the old servers 
//  We won't race another upgrade attempt because only one thread   will get the timeout from the map 
//  findbugs2.0.3 complains about get after put.   long term strategy would be use computeIfAbsent after JDK 1.8 
//  jaas.conf entry available 
//  Create the node with another session 
//  The node doesn't exist anymore, so skip it 
//  sid 
//  The first allowable character 
//  during first and second iteration, leavingIndex will correspond to a   follower   during third and fouth iteration leavingIndex will be the index of 
//  If the socket times out, we count that as Assert.failed - 
//  Make sure we can handle any type of correct wrapper 
// the direcotry containing the 
//  Sets authorization flag 
//  Setup a database with a single /foo node 
//  Sun doesn't include the address that causes this   exception to be thrown, so we wrap the exception   in order to capture this critical detail. 
//  Check that storage space return some value 
//  log that precedes first retained snapshot is also retained 
